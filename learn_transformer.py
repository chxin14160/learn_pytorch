import torch
from torch import nn
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import common


# ä¸‹è½½å™¨ä¸æ•°æ®é›†é…ç½®
# ä¸º time_machine æ•°æ®é›†æ³¨å†Œä¸‹è½½ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œæ ¡éªŒå“ˆå¸Œå€¼ï¼ˆç”¨äºéªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼‰
downloader = common.C_Downloader()
DATA_HUB = downloader.DATA_HUB  # å­—å…¸ï¼Œå­˜å‚¨æ•°æ®é›†åç§°ä¸ä¸‹è½½ä¿¡æ¯
DATA_URL = downloader.DATA_URL  # åŸºç¡€URLï¼ŒæŒ‡å‘æ•°æ®é›†çš„å­˜å‚¨ä½ç½®

# æ³¨å†Œæ•°æ®é›†ä¿¡æ¯åˆ°DATA_HUBå…¨å±€å­—å…¸
# æ ¼å¼ï¼š(æ•°æ®é›†URL, MD5æ ¡éªŒå€¼)
DATA_HUB['fra-eng'] = (DATA_URL + 'fra-eng.zip', # å®Œæ•´ä¸‹è½½URLï¼ˆDATA_URLæ˜¯d2lå®šä¹‰çš„åŸºå‡†URLï¼‰
                           '94646ad1522d915e7b0f9296181140edcf86a4f5') # æ–‡ä»¶MD5ï¼Œç”¨äºæ ¡éªŒä¸‹è½½å®Œæ•´æ€§


# print(f"10x10 çš„å•ä½çŸ©é˜µï¼ˆå¯¹è§’çº¿ä¸º 1ï¼Œå…¶ä½™ä¸º 0ï¼‰ï¼š\n{torch.eye(10)}")

# ä»…å½“æŸ¥è¯¢å’Œé”®ç›¸åŒæ—¶ï¼Œæ³¨æ„åŠ›æƒé‡ä¸º1ï¼Œå¦åˆ™ä¸º0
# torch.eye(10): ç”Ÿæˆä¸€ä¸ª 10x10 çš„å•ä½çŸ©é˜µï¼ˆå¯¹è§’çº¿ä¸º 1ï¼Œå…¶ä½™ä¸º 0ï¼‰
# .reshape((1,1,10,10)): è°ƒæ•´å½¢çŠ¶ä¸º(batch_size=1,num_heads=1,seq_len=10,seq_len=10)
# æ¨¡æ‹Ÿä¸€ä¸ªå•å¤´æ³¨æ„åŠ›æœºåˆ¶çš„æƒé‡çŸ©é˜µï¼ˆQueries Ã— Keysï¼‰
attention_weights = torch.eye(10).reshape((1, 1, 10, 10))
# common.show_heatmaps(attention_weights, xlabel='Keys', ylabel='Queries')



n_train = 50  # è®­ç»ƒæ ·æœ¬æ•°
x_train, _ = torch.sort(torch.rand(n_train) * 5) # æ’åºåçš„è®­ç»ƒæ ·æœ¬(ä»¥ä¾¿å¯è§†åŒ–)

def f(x): # éçº¿æ€§å‡½æ•°
    return 2 * torch.sin(x) + x**0.8

y_train = f(x_train) + torch.normal(0.0, 0.5, (n_train,))  # è®­ç»ƒæ ·æœ¬çš„è¾“å‡º(æ·»åŠ å™ªå£°é¡¹)
x_test = torch.arange(0, 5, 0.1) # æµ‹è¯•æ ·æœ¬
y_truth = f(x_test)              # æµ‹è¯•æ ·æœ¬çš„çœŸå®è¾“å‡º
n_test = len(x_test)             # æµ‹è¯•æ ·æœ¬æ•°
print(f"æµ‹è¯•æ ·æœ¬æ•°ï¼š{n_test}")

def plot_kernel_reg(y_hat):
    common.plot_kernel_reg(x_test, y_truth, y_hat, x_train, y_train)

def average_aggregation():
    '''ğŸ‘‰ å¹³å‡æ±‡èš'''
    # .repeat_interleave() ç”¨äºé‡å¤å¼ é‡å…ƒç´ 
    # è®¡ç®—å‡ºè®­ç»ƒæ ·æœ¬æ ‡ç­¾yçš„å‡å€¼ï¼Œç„¶åå°†å…¶é‡å¤n_testæ¬¡ï¼Œè¿”å›ä¸€ä¸ªé•¿åº¦ä¸ºn_testçš„ 1Då¼ é‡
    # å³ï¼Œç”Ÿæˆä¸€ä¸ªé•¿åº¦ä¸º n_test çš„å¼ é‡ï¼Œæ‰€æœ‰å…ƒç´ ä¸º y_trainçš„å‡å€¼ï¼Œå³ y_train.mean()
    y_hat = torch.repeat_interleave(y_train.mean(), n_test)
    # plot_kernel_reg(y_hat)
    common.plot_kernel_reg(x_test, y_truth, y_hat, x_train, y_train)
# average_aggregation()

def nonParametric_attention_aggregation():
    '''ğŸ‘‰ éå‚æ•°æ³¨æ„åŠ›æ±‡èš'''
    # 1. é‡å¤x_testä»¥åŒ¹é…æ³¨æ„åŠ›æƒé‡çš„å½¢çŠ¶
    # ä¸ºæ¯ä¸ªæµ‹è¯•æ ·æœ¬ç”Ÿæˆä¸€ä¸ªä¸ x_train å¯¹é½çš„çŸ©é˜µï¼Œä¾¿äºåç»­è®¡ç®—ç›¸ä¼¼åº¦
    # X_repeatçš„å½¢çŠ¶:(n_test,n_train),
    # æ¯ä¸€è¡Œéƒ½åŒ…å«ç€ç›¸åŒçš„æµ‹è¯•è¾“å…¥ï¼ˆä¾‹å¦‚ï¼šåŒæ ·çš„æŸ¥è¯¢ï¼‰
    # x_test.repeat_interleave(n_train) å¯¹å¼ é‡x_testçš„æ¯ä¸ªå…ƒç´ æ²¿æŒ‡å®šç»´åº¦(é»˜è®¤0)é‡å¤n_trainæ¬¡
    # å³ æ¯ä¸ªæµ‹è¯•æ ·æœ¬é‡å¤ n_train æ¬¡ï¼ˆå±•å¹³ä¸ºä¸€ç»´ï¼‰
    # .reshape((-1, n_train)) å°†å±•å¹³çš„å¼ é‡é‡æ–°è°ƒæ•´ä¸º(n_test, n_train)ï¼Œå…¶ä¸­æ¯ä¸€è¡Œæ˜¯x_testçš„ä¸€ä¸ªå‰¯æœ¬ é‡å¤n_trainæ¬¡
    X_repeat = x_test.repeat_interleave(n_train).reshape((-1, n_train))
    print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶x_test.shapeï¼š{x_test.shape}")
    print(f"å°†æµ‹è¯•æ•°æ®å…ƒç´ é‡å¤åå½¢çŠ¶ x_test.repeat_interleave(n_train).shapeï¼š"
          f"{x_test.repeat_interleave(n_train).shape}")
    print(f"é‡å¡‘å½¢çŠ¶ä¸º(n_test,n_train)ä»¥ä¾¿åç»­è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆç›¸ä¼¼åº¦è¶Šé«˜ï¼Œæ³¨æ„åŠ›æƒé‡è¶Šå¤§ï¼‰\n"
          f"x_test.repeat_interleave(n_train).reshape((-1, n_train)).shapeï¼š"
          f"{x_test.repeat_interleave(n_train).reshape((-1, n_train)).shape}")

    # 2. è®¡ç®—æ³¨æ„åŠ›æƒé‡ï¼ˆé«˜æ–¯æ ¸è½¯æ³¨æ„åŠ›ï¼‰
    # x_trainåŒ…å«ç€é”®ã€‚attention_weightsçš„å½¢çŠ¶ï¼š(n_test,n_train),
    # æ¯ä¸€è¡Œéƒ½åŒ…å«ç€è¦åœ¨ç»™å®šçš„æ¯ä¸ªæŸ¥è¯¢çš„å€¼ï¼ˆy_trainï¼‰ä¹‹é—´åˆ†é…çš„æ³¨æ„åŠ›æƒé‡
    # -(X_repeat - x_train)**2 / 2 è®¡ç®—æµ‹è¯•æ ·æœ¬ä¸è®­ç»ƒæ ·æœ¬ä¹‹é—´çš„è´Ÿæ¬§æ°è·ç¦»ï¼ˆé«˜æ–¯æ ¸çš„æŒ‡æ•°éƒ¨åˆ†ï¼‰
    # æµ‹è¯•æ•°æ®çš„è¾“å…¥X_repeat ç›¸å½“äº æŸ¥è¯¢
    # è®­ç»ƒæ•°æ®çš„è¾“å…¥x_train  ç›¸å½“äº é”®
    attention_weights = nn.functional.softmax(
        -(X_repeat - x_train)**2 / 2, # é«˜æ–¯æ ¸(è´Ÿæ¬§æ°è·ç¦»)ï¼Œç›¸ä¼¼åº¦è®¡ç®—ï¼šè·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼ˆæƒé‡è¶Šå¤§ï¼‰
        dim=1) # å¯¹æ¯ä¸€è¡Œï¼ˆæ¯ä¸ªæµ‹è¯•æ ·æœ¬ï¼‰åšsoftmaxå½’ä¸€åŒ–ï¼Œç¡®ä¿æƒé‡å’Œä¸º1

    # 3. åŠ æƒå¹³å‡å¾—åˆ°é¢„æµ‹å€¼
    # y_hatçš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯å€¼çš„åŠ æƒå¹³å‡å€¼ï¼Œå…¶ä¸­çš„æƒé‡æ˜¯æ³¨æ„åŠ›æƒé‡
    # å·¦ï¼šæ¯ä¸ªæµ‹è¯•æ ·æœ¬ å¯¹åº”æ‰€æœ‰è®­ç»ƒæ ‡ç­¾çš„å„ä¸ªæ³¨æ„åŠ›æƒé‡
    # å³ï¼šæ¯ä¸ªè®­ç»ƒæ ·æœ¬å¯¹åº”çš„æ ‡ç­¾
    y_hat = torch.matmul(attention_weights, y_train) # çŸ©é˜µä¹˜æ³•ï¼šå·¦æ‰¾è¡Œï¼Œå³æ‰¾åˆ—
    plot_kernel_reg(y_hat)

    # np.expand_dims(attention_weights, 0) åœ¨ç¬¬0è½´(æœ€å¤–å±‚)æ‰©å±•æ–°ç»´åº¦
    # np.expand_dims(np.expand_dims(attention_weights,0),0) è¿ç»­ä¸¤æ¬¡åœ¨ç¬¬0è½´(æœ€å¤–å±‚)æ‰©å±•æ–°ç»´åº¦
    # å‡è®¾attention_weightsåŸå§‹ç»´åº¦æ˜¯(3,4)ï¼Œåˆ™ç¬¬ä¸€æ¬¡æ‰©å±•å˜æˆ(1,3,4)ï¼Œåˆ™ç¬¬ä¸€æ¬¡æ‰©å±•å˜æˆ(1,1,3,4)
    common.show_heatmaps(np.expand_dims(np.expand_dims(attention_weights, 0), 0),
                      xlabel='Sorted training inputs',
                      ylabel='Sorted testing inputs') # æ˜¾ç¤ºæ³¨æ„åŠ›æƒé‡çš„çŸ©é˜µçƒ­å›¾
# nonParametric_attention_aggregation()

def parametric_attention_aggregation():
    ''' ğŸ‘‰ å¸¦å‚æ•°æ³¨æ„åŠ›æ±‡èš '''
    X = torch.ones((2, 1, 4))
    Y = torch.ones((2, 4, 6))
    print(f"æ‰¹é‡çŸ©é˜µä¹˜æ³•bmmåï¼Œç»“æœçŸ©é˜µå½¢çŠ¶ï¼š{torch.bmm(X, Y).shape}")

    # æ¼”ç¤ºæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„åŠ æƒæ±‚å’Œ
    weights = torch.ones((2, 10)) * 0.1          # å½¢çŠ¶: (æ‰¹é‡å¤§å°, åºåˆ—é•¿åº¦)-æ³¨æ„åŠ›æƒé‡
    values = torch.arange(20.0).reshape((2, 10)) # å½¢çŠ¶: (æ‰¹é‡å¤§å°, åºåˆ—é•¿åº¦)-å€¼å‘é‡
    # .unsqueeze()åœ¨æŒ‡å®šä½ç½®å¢åŠ ç»´åº¦
    print(f"åœ¨æŒ‡å®šä½ç½®å¢åŠ ç»´åº¦åçŸ©é˜µå½¢çŠ¶ï¼š\n"
          f"weightsï¼š{weights.unsqueeze(1).shape}\n"
          f"values ï¼š{values.unsqueeze(-1).shape}")
    print(f"å¢åŠ ç»´åº¦å è¿›è¡Œ æ‰¹é‡çŸ©é˜µä¹˜æ³•bmmï¼Œç»“æœä¸ºï¼š\n"
          f"ä½¿ç”¨bmmè®¡ç®—åŠ æƒå’Œ: æƒé‡(2,1,10) Ã— å€¼(2,10,1) = ç»“æœ(2,1,1) \n"
          f"{torch.bmm(weights.unsqueeze(1), values.unsqueeze(-1))}")


    class NWKernelRegression(nn.Module):
        ''' Nadaraya-Watson æ ¸å›å½’æ¨¡å‹,å®ç°åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å›å½’
        å®ç°Nadaraya-Watsonæ ¸å›å½’çš„éå‚æ•°æ–¹æ³•ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å¯¹è¾“å…¥æ•°æ®è¿›è¡ŒåŠ æƒå¹³å‡
        ä½¿ç”¨é«˜æ–¯æ ¸å‡½æ•°æ¥è®¡ç®—æŸ¥è¯¢ä¸é”®ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œå¹¶å°†è¿™äº›ç›¸ä¼¼åº¦ä½œä¸ºæƒé‡å¯¹å€¼è¿›è¡ŒåŠ æƒæ±‚å’Œ
        '''
        def __init__(self, **kwargs):
            super().__init__(**kwargs)
            # å¯å­¦ä¹ çš„å‚æ•° (é«˜æ–¯æ ¸çš„å¸¦å®½å‚æ•°)ï¼Œå³ æŸ¥è¯¢ä¸é”®é—´è·ç¦»è¦ä¹˜ä»¥çš„æƒé‡
            self.w = nn.Parameter(torch.rand((1,), requires_grad=True))

        def forward(self, queries, keys, values):
            '''
            queries : æŸ¥è¯¢è¾“å…¥ (n_query,)ï¼Œæœ‰n_queryä¸ªæŸ¥è¯¢
            keys    : è®­ç»ƒè¾“å…¥ (n_query, n_train)ï¼Œå³ æ¯ä¸ªæŸ¥è¯¢å¯¹åº”n_trainä¸ªé”®
            values  : è®­ç»ƒè¾“å‡º (n_query, n_train)
            # queries å’Œ attention_weightsçš„å½¢çŠ¶ä¸º (æŸ¥è¯¢ä¸ªæ•°ï¼Œâ€œé”®ï¼å€¼â€å¯¹ä¸ªæ•°)
            è¿”å›: åŠ æƒæ±‚å’Œåçš„é¢„æµ‹å€¼ (n_query,)
            '''
            # æ‰©å±• æŸ¥è¯¢å‘é‡querieså½¢çŠ¶ ä»¥åŒ¹é… é”®å€¼å¯¹keysçš„ç»´åº¦
            # querieså½¢çŠ¶: (æŸ¥è¯¢ä¸ªæ•°,) -> æ‰©å±•ä¸º (æŸ¥è¯¢ä¸ªæ•°, é”®å€¼å¯¹ä¸ªæ•°)
            # å°†æŸ¥è¯¢çš„æ¯ä¸ªå…ƒç´ é‡å¤ é”®çš„åˆ—æ•°æ¬¡ï¼ˆä¸ºäº†å½“å‰æŸ¥è¯¢ä¸æ¯ä¸ªé”®åšå·®ï¼‰
            # ç„¶åå°†æŸ¥è¯¢çš„å½¢çŠ¶é‡å¡‘ä¸º åˆ—ç»´ä¸é”®çš„è¡Œç»´ç›¸ç­‰çš„ çŸ©é˜µå½¢å¼ (ç¬¬iè¡Œå…ƒç´ çš†ä¸ºç¬¬iä¸ªæŸ¥è¯¢)
            # ç”±æ­¤å¯ä½¿æŸ¥è¯¢æ‹¥æœ‰ ä¸é”®ç›¸åŒçš„å½¢çŠ¶ï¼Œä»¥ä¾¿åç»­åšå·®è®¡ç®—
            queries = queries.repeat_interleave(keys.shape[1]).reshape((-1, keys.shape[1]))

            # è®¡ç®—æ³¨æ„åŠ›æƒé‡ï¼ˆä½¿ç”¨é«˜æ–¯æ ¸å‡½æ•°ï¼‰
            # å…¬å¼: attention = softmax(-(query - key)^2 * w^2 / 2)
            # æ³¨æ„åŠ›æƒé‡é€šè¿‡é«˜æ–¯æ ¸ exp(-(x_query-x_key)^2 / (2Ïƒ^2)) è®¡ç®—ï¼Œ
            # ä½¿ç”¨softmaxè¿›è¡Œå½’ä¸€åŒ–ï¼Œç¡®ä¿æ‰€æœ‰æƒé‡ä¹‹å’Œä¸º1
            self.attention_weights = nn.functional.softmax(
                -((queries - keys) * self.w) ** 2 / 2, dim=1) # å½¢çŠ¶ (n_query, n_train)

            # ä½¿ç”¨æ³¨æ„åŠ›æƒé‡å¯¹å€¼è¿›è¡ŒåŠ æƒæ±‚å’Œå¾—åˆ°é¢„æµ‹å€¼
            # bmm: (æ‰¹é‡å¤§å°, 1, é”®å€¼å¯¹ä¸ªæ•°) Ã— (æ‰¹é‡å¤§å°, é”®å€¼å¯¹ä¸ªæ•°, 1) = (æ‰¹é‡å¤§å°, 1, 1)
            # valuesçš„å½¢çŠ¶ä¸º(æŸ¥è¯¢ä¸ªæ•°ï¼Œâ€œé”®ï¼å€¼â€å¯¹ä¸ªæ•°)
            # æ³¨æ„åŠ›æƒé‡ï¼šåœ¨é™¤æ‰¹æ¬¡ç»´ä»¥å¤–çš„ç¬¬ä¸€ç»´å¢åŠ ä¸€ç»´ï¼›
            # å€¼ï¼šåœ¨æœ€åä¸€ç»´å¢åŠ ä¸€ä¸ªç»´åº¦
            # ç„¶åå„è‡ªå¢ç»´åçš„æ³¨æ„åŠ›æƒé‡ä¸å€¼ æ‰§è¡Œæ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼Œè®¡ç®—å®Œæˆåé‡å¡‘å½¢çŠ¶
            return (torch.bmm(self.attention_weights.unsqueeze(1), # (n_query, 1, n_train)
                             values.unsqueeze(-1)) # (n_query, n_train, 1)
                             .reshape(-1)) # (n_query, 1, 1) â†’ (n_query,)

    print(f"x_train.shape={x_train.shape}") # ([50])
    print(f"repeat((n_train, 1)).shape={x_train.repeat((n_train, 1)).shape}") # ([50, 50])

    # å‡†å¤‡è®­ç»ƒæ—¶çš„ keys å’Œ values ï¼ˆç”¨äºè‡ªæ³¨æ„åŠ›ï¼‰
    # X_tileçš„å½¢çŠ¶:(n_trainï¼Œn_train)ï¼Œæ¯ä¸€è¡Œéƒ½åŒ…å«ç€ç›¸åŒçš„è®­ç»ƒè¾“å…¥
    # Y_tileçš„å½¢çŠ¶:(n_trainï¼Œn_train)ï¼Œæ¯ä¸€è¡Œéƒ½åŒ…å«ç€ç›¸åŒçš„è®­ç»ƒè¾“å‡º
    # x_trainç¬¬0ç»´ç›´æ¥é‡å¤x_trainæ¬¡(å¯¹åº”è®­ç»ƒæ•°æ®çš„ä¸ªæ•°)ï¼Œç¬¬1ç»´é‡å¤ä¸€æ¬¡(ä¿æŒä¸å˜)
    # åŸæœ¬x_trainæ˜¯é•¿åº¦ä¸º50çš„å‘é‡å½¢çŠ¶ï¼Œ.repeatåå½¢çŠ¶å˜ä¸º(è®­ç»ƒæ•°æ®æ€»æ˜¯, 50)
    X_tile = x_train.repeat((n_train, 1)) # å½¢çŠ¶ (n_train * n_train, dim)
    Y_tile = y_train.repeat((n_train, 1)) # å½¢çŠ¶ (n_train * n_train, dim)

    # ï¼ˆæ’é™¤å¯¹è§’çº¿å…ƒç´ ï¼Œå³è‡ªèº«ã€‚é¿å…è‡ªåŒ¹é…ï¼‰
    # mask ç”¨äºæ’é™¤è‡ªåŒ¹é…ï¼ˆå³æŸ¥è¯¢ç‚¹ä¸ä¸è‡ªèº«è®¡ç®—æ³¨æ„åŠ›ï¼‰
    # 1ä¸å¯¹è§’çº¿ä¸º1çš„å•ä½çŸ©é˜µåšå·®ï¼Œå†è½¬æ¢ä¸ºboolç±»å‹ (ä½¿å¯¹è§’åŒºåŸŸä¸ºfalseï¼Œä»¥ä¾¿æ’é™¤)
    mask = (1 - torch.eye(n_train)).type(torch.bool) # å½¢çŠ¶ (n_train, n_train)
    # ç­‰æ•ˆäºä»¥ä¸‹ä¸¤ç§æ–¹æ³•
    # mask = ~torch.eye(n_train, dtype=torch.bool) # æ–¹æ³•2ï¼šç›´æ¥åˆ›å»ºå¸ƒå°”æ©ç ï¼ˆæ›´é«˜æ•ˆï¼‰
    # mask = (torch.eye(n_train) == 0) # æ–¹æ³•3ï¼šä½¿ç”¨æ¯”è¾ƒæ“ä½œ

    # åˆ›å»ºé”®å’Œå€¼
    # keysçš„å½¢çŠ¶  :('n_train'ï¼Œ'n_train'-1)
    # valuesçš„å½¢çŠ¶:('n_train'ï¼Œ'n_train'-1)
    # é€šè¿‡æ©ç maskä» _tileä¸­é€‰æ‹©å…ƒç´ (æ¯è¡Œå…ƒç´ çš†å°‘äº†å¯¹è§’çº¿ä½ç½®çš„é‚£ä¸ª)ï¼Œç„¶åå†é‡æ–°æ’åˆ—(è¡Œæ•°ä¸å˜)
    keys   = X_tile[mask].reshape((n_train, -1)) # å½¢çŠ¶ (n_train, n_train-1)
    values = Y_tile[mask].reshape((n_train, -1)) # å½¢çŠ¶ (n_train, n_train-1)


    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    net = NWKernelRegression()
    loss = nn.MSELoss(reduction='none') # é€å…ƒç´ è®¡ç®—æŸå¤±
    trainer = torch.optim.SGD(net.parameters(), lr=0.5)
    animator = common.Animator(xlabel='epoch', ylabel='loss', xlim=[1, 5])

    for epoch in range(5):
        trainer.zero_grad() # æ¸…é›¶æ¢¯åº¦
        # è®¡ç®—æ¯ä¸ªè®­ç»ƒç‚¹çš„é¢„æµ‹å€¼ï¼ˆqueries=x_train, keys/valuesæ¥è‡ªå…¶ä»–ç‚¹ï¼‰
        l = loss(net(x_train, keys, values), y_train) # å‰å‘ä¼ æ’­
        l.sum().backward()  # åå‘ä¼ æ’­ï¼ˆå¯¹æŸå¤±æ±‚å’Œååå‘ä¼ æ’­ï¼‰
        trainer.step()      # æ›´æ–°å‚æ•°
        print(f'epoch {epoch + 1}, loss {float(l.sum()):.6f}')
        animator.add(epoch + 1, float(l.sum()))


    # æµ‹è¯•é˜¶æ®µï¼šæ¯ä¸ªæµ‹è¯•ç‚¹ä¸æ‰€æœ‰è®­ç»ƒç‚¹è®¡ç®—æ³¨æ„åŠ›
    # keysçš„å½¢çŠ¶ :(n_testï¼Œn_train)ï¼Œæ¯ä¸€è¡ŒåŒ…å«ç€ç›¸åŒçš„è®­ç»ƒè¾“å…¥ï¼ˆä¾‹å¦‚ï¼Œç›¸åŒçš„é”®ï¼‰
    # valueçš„å½¢çŠ¶:(n_testï¼Œn_train)ï¼Œæ¯ä¸€è¡Œéƒ½åŒ…å«ç›¸åŒçš„è®­ç»ƒè¾“å‡ºï¼ˆä¾‹å¦‚ï¼Œç›¸åŒçš„å€¼ï¼‰
    # x_trainç¬¬0ç»´å…ƒç´ é‡å¤n_testæ¬¡(å¯¹åº”æµ‹è¯•æ•°æ®çš„ä¸ªæ•°)ï¼Œç¬¬2ç»´å…ƒç´ é‡å¤ä¸€æ¬¡(ä¸å˜)
    # åŸæœ¬x_trainæ˜¯é•¿åº¦ä¸º50çš„å‘é‡å½¢çŠ¶ï¼Œ.repeatåé”®å’Œå€¼çš„å½¢çŠ¶å˜ä¸º(æµ‹è¯•æ•°æ®æ€»æ•°, 50)
    keys   = x_train.repeat((n_test, 1)) # å½¢çŠ¶ (n_test, n_train)
    values = y_train.repeat((n_test, 1)) # å½¢çŠ¶ (n_test, n_train)
    y_hat = net(x_test, keys, values).unsqueeze(1).detach() # é¢„æµ‹
    plot_kernel_reg(y_hat) # ç»˜åˆ¶å›å½’ç»“æœ

    # å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡ï¼ˆæµ‹è¯•ç‚¹ vs è®­ç»ƒç‚¹ï¼‰
    # net.attention_weightså½¢çŠ¶: (n_test, n_train)
    # æ·»åŠ ä¸¤ä¸ªç»´åº¦ä½¿å…¶å˜ä¸º(1, 1, n_test, n_train)ä»¥åŒ¹é…show_heatmapsæœŸæœ›çš„4Dè¾“å…¥
    common.show_heatmaps(
        net.attention_weights.unsqueeze(0).unsqueeze(0), # å¢åŠ æ‰¹æ¬¡å’Œå¤´ç»´åº¦
        xlabel='Sorted training inputs',
        ylabel='Sorted testing inputs')
# parametric_attention_aggregation()

def attention_scoring_function():
    ''' æ³¨æ„åŠ›è¯„åˆ†å‡½æ•° '''
    # æ¼”ç¤ºï¼šæ©è”½softmaxæ“ä½œ
    print(f"ä¸¤ä¸ªæœ‰æ•ˆé•¿åº¦åˆ†åˆ«ä¸º2å’Œ3çš„ 2Ã—4çŸ©é˜µï¼Œç»è¿‡æ©è”½softmaxæ“ä½œåç»“æœï¼š\n"
          f"{common.masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3]))}")
    print(f"ä»¥äºŒç»´å¼ é‡ä½œä¸ºè¾“å…¥æŒ‡å®šæ¯è¡Œçš„æœ‰æ•ˆé•¿åº¦ï¼š\n"
          f"{common.masked_softmax(torch.rand(2, 2, 4), torch.tensor([[1, 3], [2, 4]]))}")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    # æŸ¥è¯¢ã€é”®å’Œå€¼çš„å½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ï¼Œæ­¥æ•°æˆ–è¯å…ƒåºåˆ—é•¿åº¦ï¼Œç‰¹å¾å¤§å°ï¼‰
    # å®é™…è¾“å‡º ä¸º q(2, 1, 20)ã€ k(2, 10, 2)ã€ v(2, 10, 4)
    # ä»å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1çš„æ­£æ€åˆ†å¸ƒä¸­éšæœºæŠ½å–å€¼æ¥åˆå§‹åŒ–æŸ¥è¯¢qï¼Œé”®kåˆå§‹åŒ–ä¸ºå…¨0
    queries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2))
    # valuesçš„å°æ‰¹é‡ï¼Œä¸¤ä¸ªå€¼çŸ©é˜µæ˜¯ç›¸åŒçš„
    values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)
    valid_lens = torch.tensor([2, 6]) # ä¸¤ä¸ªæ‰¹é‡çš„æœ‰æ•ˆé•¿åº¦åˆ†åˆ«ä¸º2å’Œ6

    def learn_AdditiveAttention():
        ''' åŠ æ€§æ³¨æ„åŠ›æœºåˆ¶ '''
        # æ³¨æ„åŠ›æ±‡èšè¾“å‡ºçš„å½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ï¼ŒæŸ¥è¯¢çš„æ­¥æ•°ï¼Œå€¼çš„ç»´åº¦ï¼‰
        # å°†ç‰¹å¾ç»´åº¦q20ä¸k2æ˜ å°„åˆ°åŒä¸€ç©ºé—´hidden8ï¼Œå†å¹¿æ’­
        attention = common.AdditiveAttention( # åˆå§‹åŒ–åŠ æ€§æ³¨æ„åŠ›å±‚
            key_size    =2,     # é”®å‘é‡ç»´åº¦ï¼ˆä¸keysçš„æœ€åä¸€ç»´åŒ¹é…ï¼‰
            query_size  =20,    # æŸ¥è¯¢å‘é‡ç»´åº¦ï¼ˆä¸queriesçš„æœ€åä¸€ç»´åŒ¹é…ï¼‰
            num_hiddens =8,     # éšè—å±‚å¤§å°ï¼ˆæ³¨æ„åŠ›è®¡ç®—ç©ºé—´ç»´åº¦ï¼‰
            dropout     =0.1)   # æ³¨æ„åŠ›æƒé‡éšæœºä¸¢å¼ƒç‡

        attention.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutï¼‰
        output = attention(queries, keys, values, valid_lens)
        print(f"åŠ æ€§æ³¨æ„åŠ›è¾“å‡ºç»“æœ:\n{output}")
        common.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)),
                          xlabel='Keys', ylabel='Queries')
    # learn_AdditiveAttention()

    def learn_DotProductAttention():
        ''' æ”¾ç¼©ç‚¹ç§¯æ³¨æ„åŠ›æœºåˆ¶ '''
        # æŸ¥è¯¢ä»å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1çš„æ­£æ€åˆ†å¸ƒä¸­éšæœºæŠ½å–æŒ‡æ¥åˆå§‹åŒ–
        # æ‰¹æ¬¡ä¸º2å³ä¸¤ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬1ä¸ªæŸ¥è¯¢å³1ä¸ªåºåˆ—ï¼Œåºåˆ—ç‰¹å¾å³æŸ¥è¯¢çš„ç‰¹å¾ç»´åº¦ä¸º2(ä¸é”®çš„ç‰¹å¾ç»´åº¦ç›¸åŒ)
        queries = torch.normal(0, 1, (2, 1, 2))
        # è®­ç»ƒæ—¶ä¼šéšæœºä¸¢å¼ƒ50%çš„æ³¨æ„åŠ›æƒé‡ï¼ˆå½“å‰evalæ¨¡å¼å…³é—­ï¼‰
        attention = common.DotProductAttention(dropout=0.5) # åˆå§‹åŒ–æ”¾ç¼©ç‚¹ç§¯æ³¨æ„åŠ›å±‚
        attention.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨æ“ä½œï¼‰
        output = attention(queries, keys, values, valid_lens) # å‰å‘ä¼ æ’­è®¡ç®—
        print(f"æ”¾ç¼©ç‚¹ç§¯æ³¨æ„åŠ›è¾“å‡ºç»“æœ:\n{output}")

        common.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)),
                          xlabel='Keys', ylabel='Queries')
    # learn_DotProductAttention()
# attention_scoring_function()


def learn_Bahdanau_attention():
    ''' Bahdanau æ³¨æ„åŠ› '''
    # åˆ›å»ºç¼–ç å™¨
    # å°†é•¿åº¦å¯å˜åºåˆ— â†’ å›ºå®šå½¢çŠ¶çš„ç¼–ç çŠ¶æ€
    encoder = common.Seq2SeqEncoder(vocab_size=10,  # è¯è¡¨å¤§å° å³ è¾“å…¥ç»´åº¦ä¸º10
                                    embed_size=8,   # æ¯ä¸ªå•è¯è¢«è¡¨ç¤ºä¸º8ç»´çš„å‘é‡
                                    num_hiddens=16, # éšè—å±‚çš„ç»´åº¦ å³ å•ä¸ªéšè—å±‚çš„ç¥ç»å…ƒæ•°é‡
                                    num_layers=2)   # éšè—å±‚çš„å †å æ¬¡æ•°
    encoder.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰

    # åˆ›å»ºå¸¦æ³¨æ„åŠ›çš„è§£ç å™¨
    # å›ºå®šå½¢çŠ¶çš„ç¼–ç çŠ¶æ€ â†’ å°†é•¿åº¦å¯å˜åºåˆ—
    decoder = common.Seq2SeqAttentionDecoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)
    decoder.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰

    # åˆ›å»ºè¾“å…¥æ•°æ® (batch_size=4, åºåˆ—é•¿åº¦=7)
    # æ€»å…±4ä¸ªæ‰¹æ¬¡æ•°æ®ï¼Œæ¯æ‰¹æ¬¡æ•°æ®çš„é•¿åº¦ å³ æ—¶é—´æ­¥ ä¸º7
    X = torch.zeros((4, 7), dtype=torch.long)  # (batch_size,num_steps)

    # ç¼–ç å™¨å¤„ç†
    # è¿™é‡Œç¼–ç å™¨å‡ºæ¥outputå½¢çŠ¶:(batch_size,num_steps,num_hiddens)ï¼ˆPyTorchçš„GRUé»˜è®¤è¾“å‡ºæ ¼å¼ï¼‰
    # stateå½¢çŠ¶:(num_layers,batch_size,num_hiddens)
    enc_outputs = encoder(X)  # outputs: (4,7,16), hidden_state: (2,4,16)

    # åˆå§‹åŒ–è§£ç å™¨çŠ¶æ€
    # å°†ç¼–ç å™¨çš„è¾“å‡ºè½¬æ¢æˆ è§£ç å™¨æ‰€éœ€çš„çŠ¶æ€
    state = decoder.init_state(enc_outputs, None) # outputsè°ƒæ•´ä¸º(7,4,16)
    output, state = decoder(X, state) # å‰å‘ä¼ æ’­ï¼šè§£ç ï¼ˆå‡è®¾è¾“å…¥Xä½œä¸ºåˆå§‹è¾“å…¥ï¼‰

    # æ£€æŸ¥è¾“å‡ºç»´åº¦å’ŒçŠ¶æ€ç»“æ„
    print(f"æŠ•å½±åˆ°è¯è¡¨ç©ºé—´çš„æ‰€æœ‰æ—¶é—´æ­¥è¾“å‡ºå½¢çŠ¶ï¼š{output.shape}") # é¢„æœŸ: torch.Size([4, 7, 10])
    print(f"æ›´æ–°åçš„è§£ç å™¨çŠ¶æ€ä¸‰å…ƒç»„é•¿åº¦ï¼š{len(state)}") # 3: [enc_outputs, hidden_state, enc_valid_lens]
    print(f"ç¼–ç å™¨è¾“å‡º: {state[0].shape}")       # torch.Size([4, 7, 16])
    print(f"è§£ç å™¨éšè—çŠ¶æ€çš„å±‚æ•°ï¼š{len(state[1])}")
    print(f"é¦–å±‚éšè—çŠ¶æ€å½¢çŠ¶: {state[1][0].shape}")  # torch.Size([4, 16])


    # è¯åµŒå…¥ç»´åº¦ï¼Œéšè—å±‚ç»´åº¦ï¼Œrnnå±‚æ•°ï¼Œå¤±æ´»ç‡
    embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1
    batch_size, num_steps = 64, 10 # æ‰¹é‡å¤§å°ï¼Œåºåˆ—æœ€å¤§é•¿åº¦
    lr, num_epochs, device = 0.005, 250, common.try_gpu() # å­¦ä¹ ç‡ï¼Œè®­ç»ƒè½®æ•°ï¼Œè®¾å¤‡é€‰æ‹©

    """ æ•°æ®é¢„å¤„ç†
    train_iter: è®­ç»ƒæ•°æ®è¿­ä»£å™¨ï¼ˆè‡ªåŠ¨è¿›è¡Œåˆ†è¯ã€æ„å»ºè¯æ±‡è¡¨ã€å¡«å……å’Œæ‰¹å¤„ç†ï¼‰
    src_vocab/tgt_vocab: æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€çš„è¯æ±‡è¡¨å¯¹è±¡ï¼ˆåŒ…å«è¯å…ƒåˆ°ç´¢å¼•çš„æ˜ å°„ï¼‰
    """
    train_iter, src_vocab, tgt_vocab = common.load_data_nmt(downloader, batch_size, num_steps)

    # æ¨¡å‹æ„å»º
    """
    ç¼–ç å™¨ç»“æ„ï¼š
    - åµŒå…¥å±‚ï¼šå°†è¯å…ƒç´¢å¼•æ˜ å°„ä¸º32ç»´å‘é‡
    - GRUå±‚ï¼š2å±‚å †å ï¼Œæ¯å±‚32ä¸ªéšè—å•å…ƒï¼Œå¸¦0.1çš„dropout
    - è¾“å‡ºï¼šæ‰€æœ‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼ˆç”¨äºæ³¨æ„åŠ›è®¡ç®—ï¼‰å’Œæœ€ç»ˆéšè—çŠ¶æ€ï¼ˆåˆå§‹åŒ–è§£ç å™¨ï¼‰
    """
    encoder = common.Seq2SeqEncoder(
        len(src_vocab), embed_size, num_hiddens, num_layers, dropout)
    """
    è§£ç å™¨æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
    - æ³¨æ„åŠ›æœºåˆ¶ï¼šåŠ æ€§æ³¨æ„åŠ›ï¼ˆBahdanaué£æ ¼ï¼‰ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥åŠ¨æ€ç”Ÿæˆä¸Šä¸‹æ–‡å‘é‡
    - è¾“å…¥æ‹¼æ¥ï¼šè¯åµŒå…¥ï¼ˆ32ç»´ï¼‰ä¸ä¸Šä¸‹æ–‡å‘é‡ï¼ˆ32ç»´ï¼‰æ‹¼æ¥ä¸º64ç»´è¾“å…¥
    - GRUå±‚ï¼šä¸ç¼–ç å™¨ç»´åº¦å¯¹é½ï¼Œä¿æŒ2å±‚å †å ç»“æ„
    """
    decoder = common.Seq2SeqAttentionDecoder(
        len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)
    net = common.EncoderDecoder(encoder, decoder)  # å°è£…ç¼–ç å™¨-è§£ç å™¨ç»“æ„

    """ æ¨¡å‹è®­ç»ƒ
    è®­ç»ƒè¿‡ç¨‹ç‰¹ç‚¹ï¼š
    - æŸå¤±å‡½æ•°ï¼šäº¤å‰ç†µæŸå¤±ï¼ˆå¿½ç•¥å¡«å……ç¬¦ï¼‰
    - ä¼˜åŒ–å™¨ï¼šAdam
    - æ­£åˆ™åŒ–ï¼šæ¢¯åº¦è£å‰ªï¼ˆé˜²æ¢¯åº¦çˆ†ç‚¸ï¼‰+ Dropout
    - æ•™å¸ˆå¼ºåˆ¶ï¼ˆTeacher Forcingï¼‰ï¼šè®­ç»ƒæ—¶ä½¿ç”¨çœŸå®æ ‡ç­¾ä½œä¸ºè¾“å…¥
    """
    common.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)

    # æ¨ç†ä¸è¯„ä¼°
    engs = ['go .', "i lost .", 'he\'s calm .', 'i\'m home .']
    fras = ['va !', 'j\'ai perdu .', 'il est calme .', 'je suis chez moi .']
    for eng, fra in zip(engs, fras):
        # å¸¦æ³¨æ„åŠ›å¯è§†åŒ–çš„é¢„æµ‹
        translation, dec_attention_weight_seq = common.predict_seq2seq(
            net, eng, src_vocab, tgt_vocab, num_steps, device, True)
        # BLEU-2è¯„ä¼°ï¼ˆåŒè¯ç»„åŒ¹é…ç²¾åº¦ï¼‰
        print(f'{eng} => {translation}, ',
              f'bleu {common.bleu(translation, fra, k=2):.3f}')

    # æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–å¤„ç†
    """
    æ•°æ®å¤„ç†é€»è¾‘ï¼š
    éå†dec_attention_weight_seqï¼ˆè§£ç å™¨å„æ—¶é—´æ­¥çš„æ³¨æ„åŠ›æƒé‡åºåˆ—ï¼‰
    step[0][0][0]å³é¦–ä¸ªbatchã€é¦–ä¸ªå¤´ã€é¦–ä¸ªæŸ¥è¯¢ä½ç½®å¯¹åº”çš„æ‰€æœ‰é”®çš„æƒé‡ï¼ˆå½¢çŠ¶ä¸º(key_len,)ï¼‰
    1. æå–æ¯ä¸ªæ—¶é—´æ­¥çš„æ³¨æ„åŠ›æƒé‡çŸ©é˜µï¼ˆbatch_size=1, num_heads=1, query_pos, key_posï¼‰
    2. .cat(, 0)æ²¿æ—¶é—´ç»´åº¦æ‹¼æ¥æ‰€æœ‰æƒé‡çŸ©é˜µ
    3. .reshape()è°ƒæ•´å½¢çŠ¶ä¸º(1, 1, num_queries, num_keys)
    """
    attention_weights = torch.cat([step[0][0][0] for step in dec_attention_weight_seq], 0).reshape((
        1, 1, -1, num_steps))

    """ ç»˜åˆ¶æ³¨æ„åŠ›çƒ­å›¾
    å¯è§†åŒ–è¯´æ˜ï¼š
    - æ¨ªè½´ï¼šæºè¯­è¨€å¥å­ä½ç½®ï¼ˆç¼–ç å™¨æ—¶é—´æ­¥ï¼‰
    - çºµè½´ï¼šç›®æ ‡è¯­è¨€ç”Ÿæˆä½ç½®ï¼ˆè§£ç å™¨æ—¶é—´æ­¥ï¼‰
    - é¢œè‰²æ·±æµ…ï¼šæ³¨æ„åŠ›æƒé‡å¤§å°ï¼ˆçº¢è‰²è¶Šæ·±è¡¨ç¤ºå…³æ³¨åº¦è¶Šé«˜ï¼‰
    - å…¸å‹å¯¹é½æ¨¡å¼ï¼šå¯¹è§’çº¿ï¼ˆå•è°ƒå¯¹é½ï¼‰ã€æ–œçº¿ï¼ˆè·¨è¯å¯¹é½ï¼‰
    """
    # åŠ ä¸Šä¸€ä¸ªåŒ…å«åºåˆ—ç»“æŸè¯å…ƒ
    common.show_heatmaps(
        attention_weights[:, :, :, :len(engs[-1].split()) + 1].cpu(),
        xlabel='Key positions', ylabel='Query positions')
# learn_Bahdanau_attention()


def learn_MultiHeadAttention():
    ''' å­¦ä¹  å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ '''
    num_hiddens, num_heads = 100, 5 # éšè—å±‚ç»´åº¦ï¼Œæ³¨æ„åŠ›å¤´æ•°
    attention = common.MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,
                                   num_hiddens, num_heads, 0.5)
    attention.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰
    print(f"[å¤šå¤´æ³¨æ„åŠ›]æ¨¡å‹ç»“æ„æ¦‚è§ˆï¼š\n{attention}")

    batch_size, num_queries = 2, 4 # æ‰¹é‡å¤§å°ï¼ŒæŸ¥è¯¢æ•°é‡
    # é”®å€¼å¯¹æ•°ï¼Œåºåˆ—æœ‰æ•ˆé•¿åº¦
    # (å› ä¸ºæ‰¹é‡å¤§å°ä¸º2ï¼Œæ‰€ä»¥ç¬¬ä¸€ä¸ªæ‰¹é‡çš„åºåˆ—é•¿åº¦ä¸­æœ‰æ•ˆé•¿åº¦ä¸º3ï¼Œç¬¬äºŒä¸ªæ‰¹é‡çš„åºåˆ—é•¿åº¦ä¸­æœ‰æ•ˆé•¿åº¦ä¸º2)
    # åºåˆ—é•¿åº¦ï¼šå¯¹äºXæ¥è¯´æ˜¯æŸ¥è¯¢æ•°4ï¼Œå¯¹äºYæ¥è¯´æ˜¯é”®å€¼å¯¹æ•°6
    num_kvpairs, valid_lens = 6, torch.tensor([3, 2]) # ç¬¬äºŒä¸ªæŸ¥è¯¢åªå…³æ³¨å‰2ä¸ªé”®å€¼å¯¹

    # è¾“å…¥æ•°æ®ï¼šå…¨1å¼ é‡ç”¨äºæµ‹è¯•
    # Xçš„å½¢çŠ¶æ˜¯(batch_size, num_queries, num_hiddens)
    # å³ æ¯ä¸ªæ ·æœ¬æœ‰num_queriesä¸ªæŸ¥è¯¢å‘é‡ï¼Œæ¯ä¸ªå‘é‡ç»´åº¦æ˜¯num_hiddens
    # Yçš„å½¢çŠ¶æ˜¯(batch_size, num_kvpairs, num_hiddens)
    # å³ æ¯ä¸ªæ ·æœ¬æœ‰num_kvpairsä¸ªé”®å€¼å¯¹ï¼Œæ¯ä¸ªé”®å’Œå€¼çš„ç»´åº¦ä¹Ÿæ˜¯num_hiddens
    X = torch.ones((batch_size, num_queries, num_hiddens)) # æŸ¥è¯¢å‘é‡
    Y = torch.ones((batch_size, num_kvpairs, num_hiddens)) # é”®å€¼å¯¹

    # å‰å‘ä¼ æ’­
    output = attention(X, Y, Y, valid_lens)
    print(f"è¾“å‡ºå½¢çŠ¶ï¼š{output.shape}")
# learn_MultiHeadAttention()


def Self_attention_and_position_encoding():
    ''' è‡ªæ³¨æ„åŠ›å’Œä½ç½®ç¼–ç  '''
    # è‡ªæ³¨æ„åŠ›ï¼ˆqkvçš†ä¸ºåŒä¸€åºåˆ—ï¼‰
    num_hiddens, num_heads = 100, 5 # éšè—å±‚ç»´åº¦ï¼Œæ³¨æ„åŠ›å¤´æ•°
    attention = common.MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,
                                       num_hiddens, num_heads, 0.5)
    attention.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰
    print(f"æ¨¡å‹ç»“æ„ï¼š\n{attention}")

    # æ‰¹é‡å¤§å°ï¼ŒæŸ¥è¯¢æ•°é‡ï¼Œåºåˆ—æœ‰æ•ˆé•¿åº¦(å¯¹äºXæ¥è¯´ï¼Œåºåˆ—é•¿åº¦æ˜¯é”®å€¼å¯¹æ•°)
    batch_size, num_queries, valid_lens = 2, 4, torch.tensor([3, 2])
    # è¾“å…¥æ•°æ®ï¼šå…¨1å¼ é‡ç”¨äºæµ‹è¯•
    # å¼ é‡å½¢çŠ¶ï¼ˆæ‰¹é‡å¤§å°ï¼Œæ—¶é—´æ­¥çš„æ•°ç›®æˆ–è¯å…ƒåºåˆ—çš„é•¿åº¦ï¼Œdï¼‰
    # æŸ¥è¯¢æ•°é‡ï¼Œç­‰åŒäºåºåˆ—é•¿åº¦ï¼ˆæ—¶é—´æ­¥æ•°/è¯å…ƒæ•°ï¼‰ï¼Œè¡¨ç¤ºæ¯ä¸ªåºåˆ—åŒ…å«çš„è¯å…ƒæ•°é‡ï¼ˆæ­¤å¤„ä¸º4ï¼‰
    # dï¼šéšè—å±‚ç»´åº¦ï¼ˆå³ç‰¹å¾å‘é‡é•¿åº¦ï¼‰
    X = torch.ones((batch_size, num_queries, num_hiddens))
    output = attention(X, X, X, valid_lens)
    print(f"è¾“å‡ºå½¢çŠ¶ï¼š{output.shape}")


    encoding_dim, num_steps = 32, 60 # åµŒå…¥ç»´åº¦ï¼Œåºåˆ—æ­¥é•¿
    pos_encoding = common.PositionalEncoding(encoding_dim, 0) # åˆ›å»ºä½ç½®ç¼–ç å™¨
    pos_encoding.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰

    # ç”Ÿæˆå…¨é›¶è¾“å…¥ï¼ˆæ¨¡æ‹ŸåµŒå…¥å‘é‡ï¼‰
    # â‘ torch.zeros((1, num_steps, encoding_dim)) å’Œ
    # â‘¡torch.zeros(1, num_steps, encoding_dim) å®Œå…¨ç­‰æ•ˆï¼Œæ— åŠŸèƒ½å·®å¼‚
    # â‘ æ˜¯ å…ƒç»„å½¢å¼   ï¼Œç¬¦åˆå‡½æ•°å‚æ•°ä¼ é€’çš„é€šç”¨è§„èŒƒ
    # â‘¡æ˜¯ ç›´æ¥å‚æ•°å½¢å¼ï¼Œç›´æ¥ä¼ é€’å¤šä¸ªæ•´æ•°å‚æ•°ï¼ŒPyTorchå†…éƒ¨ä¼šè‡ªåŠ¨å°†å…¶è½¬æ¢ä¸ºå½¢çŠ¶å…ƒç»„
    X = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))
    # å¤–éƒ¨å†æ¬¡æå–æ“ä½œï¼šæœåŠ¡äºåç»­å¤„ç†éœ€æ±‚
    P = pos_encoding.P[:, :X.shape[1], :] # æå–å®é™…ä½¿ç”¨çš„ä½ç½®ç¼–ç 

    ''' å¯è§†åŒ–ç‰¹å®šç»´åº¦çš„ä½ç½®ç¼–ç å˜åŒ–
    P[0, :, 6:10]å–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡(batchç»´åº¦ç´¢å¼•0)ï¼Œè¯¥æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰è¯å…ƒ(åºåˆ—ç»´åº¦å…¨éƒ¨ä¿ç•™ï¼Œä»0åˆ°seq_len-1)
          å–æ¯ä¸ªè¯å…ƒçš„ç‰¹å¾ç»´åº¦ä¸­ç´¢å¼•6åˆ°9çš„4ä¸ªç»´åº¦ï¼ˆå¯¹åº”éšè—å±‚ç»´åº¦ç´¢å¼•6,7,8,9ï¼‰
          
    åŠ è½¬ç½®çš„åŸå› ï¼šè°ƒæ•´æ•°æ®çš„ç»´åº¦ï¼Œä½¿èƒ½æ­£ç¡®å°†æ¯ä¸ªç‰¹å¾ç»´åº¦ä½œä¸ºå•ç‹¬çš„æ›²çº¿ç»˜åˆ¶ï¼Œè€Œéå°†æ¯ä¸ªä½ç½®ä½œä¸ºæ›²çº¿
        è‹¥åŸå§‹æ•°æ®æ˜¯ï¼š
            ä½ç½®0: [v6, v7, v8, v9]
            ä½ç½®1: [v6, v7, v8, v9]
        è½¬ç½®åå˜æˆï¼š
            ç‰¹å¾6: [ä½ç½®0çš„å€¼, ä½ç½®1çš„å€¼, ...]
            ç‰¹å¾7: [ä½ç½®0çš„å€¼, ä½ç½®1çš„å€¼, ...]
    è¿™æ ·ï¼Œæ¯æ¡æ›²çº¿å°±æ˜¯æŸä¸ªç‰¹å¾ç»´åº¦éšä½ç½®çš„å˜åŒ–ï¼Œç¬¦åˆå¸¸è§çš„å¯è§†åŒ–éœ€æ±‚
    
    legend=["Col %d" % d for d in torch.arange(6, 10)] ç­‰ä»·äº
    legend=[f"Col {d}" for d in range(6, 10)]
    '''
    common.plot(torch.arange(num_steps),    # xè½´ï¼š0~59çš„ä½ç½®ç´¢å¼•
                P[0, :, 6:10].T,            # é€‰å–ç»´åº¦6~9çš„4ä¸ªç‰¹å¾
                xlabel='Row (position)',    # xè½´æ ‡ç­¾
                figsize=(6, 2.5),           # å›¾åƒå°ºå¯¸
                legend=["Col %d" % d for d in torch.arange(6, 10)]) # å›¾ä¾‹

    # æ‰“å°0åˆ°7çš„äºŒè¿›åˆ¶è¡¨ç¤ºå½¢å¼ï¼Œæ¼”ç¤ºè§‚ç‚¹ï¼šéšç€ç¼–ç ç»´åº¦å¢åŠ ï¼Œæ¯”ç‰¹å€¼çš„äº¤æ›¿é¢‘ç‡æ­£åœ¨å•è°ƒé™ä½
    for i in range(8):
        print(f'{i}çš„äºŒè¿›åˆ¶æ˜¯ï¼š{i:>03b}') # æ ¼å¼åŒ–è¾“å‡ºäºŒè¿›åˆ¶ï¼ˆ3ä½å®½åº¦å³å¯¹é½ï¼‰

    # çƒ­å›¾å¯è§†åŒ–ï¼šå±•ç¤ºä½ç½®ç¼–ç çŸ©é˜µçš„å…¨å±€æ¨¡å¼
    # å–å‡ºç¬¬ä¸€ä¸ªæ‰¹æ¬¡(batchç»´åº¦ç´¢å¼•0)çš„æ‰€æœ‰è¯å…ƒçš„å’Œæ‰€æœ‰ç‰¹å¾ç»´åº¦ï¼Œåœ¨ç¬¬0ç»´çš„ä½ç½®æ’å…¥ä¸¤ä¸ªé•¿åº¦ä¸º1çš„ç»´åº¦
    # æ’å…¥çš„ä¸¤ä¸ªé•¿åº¦ä¸º1çš„ç»´åº¦æ˜¯æŒ‡å­å›¾è¡Œæ•°å’Œåˆ—æ•°ï¼Œ
    # å¤šä¸ªå­å›¾æŒ‡çš„æ˜¯å°†å¤šä¸ªä¸åŒçš„çƒ­å›¾å­å›¾æ˜¾ç¤ºåœ¨åŒä¸€ä¸ªç”»æ¡†ï¼ˆå³ä¸€ä¸ªå›¾å½¢çª—å£ï¼‰å†…ï¼Œè€Œè¿™é‡Œåªæœ‰ä¸€ä¸ªå­å›¾çƒ­å›¾
    P = P[0, :, :].unsqueeze(0).unsqueeze(0) # è°ƒæ•´ç»´åº¦ä¸º(1,1,seq_len,dim)
    common.show_heatmaps(P,
                         xlabel='Column (encoding dimension)', # xè½´ï¼šç¼–ç ç»´åº¦
                         ylabel='Row (position)',              # yè½´ï¼šåºåˆ—ä½ç½®
                         figsize=(3.5, 4),
                         cmap='Blues') # è“è‰²ç³»é…è‰²
# Self_attention_and_position_encoding()


def test_PositionWise_FFN():
    ''' æµ‹è¯•ï¼šåŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ
    (å¯¹æ¯ä¸ªè¾“å…¥çš„xéƒ½ç‹¬ç«‹åº”ç”¨ç›¸åŒçš„çº¿æ€§+æ¿€æ´»+çº¿æ€§) '''
    # åˆ›å»ºFFNå®ä¾‹ï¼šè¾“å…¥ç»´åº¦4ï¼Œéšè—å±‚8ï¼Œè¾“å‡ºç»´åº¦8ï¼ˆå®é™…å¸¸ç”¨éšè—å±‚ç»´åº¦è¿œå¤§äºè¾“å…¥/è¾“å‡ºï¼‰
    # æ³¨ï¼šæ­¤å¤„éšè—å±‚ç»´åº¦è®¾ä¸º4ä»…ä¸ºç¤ºä¾‹ï¼Œå®é™…å¸¸è®¾ä¸º2048ç­‰å¤§å€¼
    ffn = common.PositionWiseFFN(4, 4, 8)
    ffn.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰

    # åˆ›å»ºè¾“å…¥æ•°æ®ï¼š2ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬3ä¸ªä½ç½®ï¼Œæ¯ä¸ªä½ç½®4ç»´ç‰¹å¾
    input_tensor = torch.ones((2, 3, 4))  # å…¨1å¼ é‡ç”¨äºæµ‹è¯•
    output = ffn(input_tensor)      # æ‰§è¡Œå‰å‘ä¼ æ’­
    first_sample_output = output[0] # è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ‰€æœ‰ä½ç½®è¾“å‡ºï¼ˆå½¢çŠ¶ï¼š3ä¸ªä½ç½® Ã— 8ç»´è¾“å‡ºï¼‰
    print("è¾“å…¥å½¢çŠ¶:", input_tensor.shape)  # torch.Size([2, 3, 4])
    print("è¾“å‡ºå½¢çŠ¶:", output.shape)        # torch.Size([2, 3, 8])
    print("é¦–æ ·æœ¬è¾“å‡º:\n", first_sample_output)
# test_PositionWise_FFN()

def test_Add_and_Norm():
    ''' æµ‹è¯•ï¼šæ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ– æ¨¡å—
    æ®‹å·®è¾“å…¥xç»è¿‡éšæœºå¤±æ´»åï¼Œä¸å­å±‚è¾“å‡ºyç›¸åŠ ï¼Œ
    ç›¸åŠ åå†ç»è¿‡å±‚å½’ä¸€åŒ–(æ ·æœ¬å†…æ‰€æœ‰ç‰¹å¾ç»è¿‡å½’ä¸€åŒ–ï¼Œå³æ¯ä¸ªå­¦ç”Ÿçš„æ‰€æœ‰ç§‘ç›®æˆç»©å½’ä¸€åŒ–)'''
    ln = nn.LayerNorm(2)    # åˆ›å»ºã€å±‚ã€‘å½’ä¸€åŒ–å¯¹è±¡ï¼ˆå¯¹æ¯ä¸ªæ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾å½’ä¸€åŒ–ï¼‰
    bn = nn.BatchNorm1d(2)  # åˆ›å»ºã€æ‰¹ã€‘å½’ä¸€åŒ–å¯¹è±¡ï¼ˆå¯¹æ¯ä¸ªç‰¹å¾è·¨æ ·æœ¬å½’ä¸€åŒ–ï¼‰

    # åˆ›å»ºè¾“å…¥æ•°æ®ï¼š2ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬2ä¸ªç‰¹å¾
    X = torch.tensor([[1, 2], [2, 3]], dtype=torch.float32)
    print("åœ¨è®­ç»ƒæ¨¡å¼ä¸‹è®¡ç®—Xçš„å‡å€¼å’Œæ–¹å·®:\n")
    # å±‚å½’ä¸€åŒ–è®¡ç®—ï¼ˆæ¯ä¸ªæ ·æœ¬ç‹¬ç«‹å½’ä¸€åŒ–ï¼‰
    print('layer norm:', ln(X))  # æ¯ä¸ªæ ·æœ¬çš„å‡å€¼å’Œæ–¹å·®ç‹¬ç«‹è®¡ç®—
    # æ‰¹å½’ä¸€åŒ–è®¡ç®—ï¼ˆè·¨æ ·æœ¬å½’ä¸€åŒ–ï¼‰
    print('batch norm:', bn(X))  # æ‰€æœ‰æ ·æœ¬çš„åŒä¸€ç‰¹å¾å…±äº«å‡å€¼å’Œæ–¹å·®

    # AddNormæ¨¡å—ä½¿ç”¨ç¤ºä¾‹
    # åˆ›å»ºAddNormå®ä¾‹ï¼šè¾“å…¥å¼ é‡æœ€åç»´åº¦ä¸º4ï¼ŒDropoutæ¦‚ç‡0.5
    add_norm = common.AddNorm([3, 4], 0.5)
    add_norm.eval() # åˆ‡æ¢è‡³è¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­Dropoutï¼ŒBatchNormä½¿ç”¨ç§»åŠ¨å¹³å‡ï¼‰

    # åˆ›å»ºè¾“å…¥æ•°æ®ï¼š2ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬3ä¸ªä½ç½®ï¼Œæ¯ä¸ªä½ç½®4ç»´ç‰¹å¾
    input1 = torch.ones((2, 3, 4))
    input2 = torch.ones((2, 3, 4))  # æ®‹å·®è¿æ¥è¾“å…¥
    output = add_norm(input1, input2) #å‰å‘ä¼ æ’­
    print("è¾“å‡ºå½¢çŠ¶éªŒè¯ï¼ˆåº”ä¸è¾“å…¥ç›¸åŒï¼‰\n"
          "è¾“å‡ºå½¢çŠ¶:", output.shape)  # torch.Size([2, 3, 4])
# test_Add_and_Norm()



def test_transformer_encoder():
    ''' æµ‹è¯•ï¼štransformerçš„ç¼–ç å™¨å—åŠç¼–ç å™¨ '''
    # æµ‹è¯•ä»£ç ï¼ˆéªŒè¯ç»´åº¦å˜æ¢ï¼‰
    X = torch.ones((2, 100, 24)) # æ¨¡æ‹Ÿè¾“å…¥ [batch_size=2, seq_length=100, dim=24]
    valid_lens = torch.tensor([3, 2]) # æœ‰æ•ˆé•¿åº¦æ©ç 

    # åˆ›å»ºç¼–ç å™¨å—
    encoder_blk = common.EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)
    encoder_blk.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰
    output = encoder_blk(X, valid_lens)
    print(f"ç¼–ç å™¨å—è¾“å‡ºå½¢çŠ¶ï¼š{output.shape}")

    # åˆ›å»ºå®Œæ•´ç¼–ç å™¨
    encoder = common.TransformerEncoder(
        200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)
    encoder.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰
    output = encoder(torch.ones((2, 100), dtype=torch.long), valid_lens)
    print(f"ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶ï¼š{output.shape}")
# test_transformer_encoder()


def test_transformer_encoder():
    ''' æµ‹è¯•ï¼štransformerçš„è§£ç å™¨å— '''
    # åˆ›å»ºç¼–ç å™¨å—
    encoder_blk = common.EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)
    encoder_blk.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰

    # åˆ›å»ºè§£ç å™¨å—
    decoder_blk = common.DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0)
    decoder_blk.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰

    X = torch.ones((2, 100, 24)) # æ¨¡æ‹Ÿè¾“å…¥ [batch_size=2, seq_length=100, dim=24]
    valid_lens = torch.tensor([3, 2]) # æœ‰æ•ˆé•¿åº¦æ©ç 

    state = [encoder_blk(X, valid_lens), valid_lens, [None]] # æ„å»ºè§£ç å™¨çŠ¶æ€
    output = decoder_blk(X, state) # å‰å‘ä¼ æ’­
    print(f"è§£ç å™¨å—è¾“å‡ºï¼Œç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„å½¢çŠ¶ï¼š{output[0].shape}") # torch.Size([2, 100, 24])
# test_transformer_encoder()


# é…ç½®è¶…å‚æ•°
num_hiddens = 32  # éšè—å±‚ç»´åº¦ï¼ˆTransformerç‰¹å¾ç»´åº¦ï¼‰
num_layers = 2  # ç¼–ç å™¨/è§£ç å™¨å †å å±‚æ•°
dropout = 0.1  # éšæœºå¤±æ´»æ¦‚ç‡ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
batch_size = 64  # è®­ç»ƒæ‰¹æ¬¡å¤§å°
num_steps = 10  # åºåˆ—æœ€å¤§é•¿åº¦ï¼ˆé˜²æ­¢è¿‡é•¿åºåˆ—ï¼‰
lr = 0.005  # å­¦ä¹ ç‡ï¼ˆAdamä¼˜åŒ–å™¨ï¼‰
num_epochs = 200  # è®­ç»ƒè½®æ¬¡
device = common.try_gpu()  # è‡ªåŠ¨é€‰æ‹©GPU/CPU

# å‰é¦ˆç½‘ç»œå‚æ•°
ffn_num_input = 32  # å‰é¦ˆç½‘ç»œè¾“å…¥ç»´åº¦ï¼ˆç­‰äºnum_hiddensï¼‰
ffn_num_hiddens = 64  # å‰é¦ˆç½‘ç»œä¸­é—´å±‚ç»´åº¦ï¼ˆé€šå¸¸ä¸º4å€è¾“å…¥ç»´åº¦ï¼‰
num_heads = 4  # å¤šå¤´æ³¨æ„åŠ›å¤´æ•°

# æ³¨æ„åŠ›æœºåˆ¶å‚æ•°
key_size = query_size = value_size = 32  # K/Q/Vå‘é‡ç»´åº¦
norm_shape = [32]  # å±‚å½’ä¸€åŒ–ç»´åº¦ï¼ˆä¸num_hiddensä¸€è‡´ï¼‰

# åŠ è½½æœºå™¨ç¿»è¯‘æ•°æ®é›†ï¼ˆä¸­è‹±ç¿»è¯‘ç¤ºä¾‹ï¼‰
# è¿”å›ï¼šæ•°æ®è¿­ä»£å™¨ã€æºè¯­è¨€è¯æ±‡è¡¨ã€ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨
train_iter, src_vocab, tgt_vocab = common.load_data_nmt(downloader, batch_size, num_steps)

# æ„å»ºTransformerç¼–ç å™¨
encoder = common.TransformerEncoder(
    vocab_size=len(src_vocab),    # æºè¯­è¨€è¯æ±‡è¡¨å¤§å°
    key_size=key_size,             # é”®å‘é‡ç»´åº¦
    query_size=query_size,         # æŸ¥è¯¢å‘é‡ç»´åº¦
    value_size=value_size,         # å€¼å‘é‡ç»´åº¦
    num_hiddens=num_hiddens,       # éšè—å±‚ç»´åº¦
    norm_shape=norm_shape,         # å±‚å½’ä¸€åŒ–å½¢çŠ¶
    ffn_num_input=ffn_num_input,   # å‰é¦ˆç½‘ç»œè¾“å…¥ç»´åº¦
    ffn_num_hiddens=ffn_num_hiddens, # å‰é¦ˆç½‘ç»œä¸­é—´å±‚ç»´åº¦
    num_heads=num_heads,           # å¤šå¤´æ³¨æ„åŠ›å¤´æ•°
    num_layers=num_layers,         # ç¼–ç å™¨å±‚æ•°
    dropout=dropout               # éšæœºå¤±æ´»æ¦‚ç‡
)

# æ„å»ºTransformerè§£ç å™¨
decoder = common.TransformerDecoder(
    vocab_size=len(tgt_vocab),    # ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨å¤§å°
    # å…¶ä»–å‚æ•°ä¸ç¼–ç å™¨é…ç½®ä¸€è‡´
    key_size=key_size,
    query_size=query_size,
    value_size=value_size,
    num_hiddens=num_hiddens,
    norm_shape=norm_shape,
    ffn_num_input=ffn_num_input,
    ffn_num_hiddens=ffn_num_hiddens,
    num_heads=num_heads,
    num_layers=num_layers,
    dropout=dropout
)

# ç»„åˆç¼–ç å™¨-è§£ç å™¨æ¶æ„
net = common.EncoderDecoder(encoder, decoder)

# è®­ç»ƒåºåˆ—åˆ°åºåˆ—æ¨¡å‹
# æ¨¡å‹ï¼Œè®­ç»ƒæ•°æ®è¿­ä»£å™¨ï¼Œå­¦ä¹ ç‡ï¼Œè®­ç»ƒè½®æ¬¡ï¼Œç›®æ ‡è¯­è¨€è¯æ±‡è¡¨ï¼ˆç”¨äºè¯„ä¼°ï¼‰ï¼Œè®­ç»ƒè®¾å¤‡
common.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)


# è‹±æ³•å¯¹ç…§æµ‹è¯•é›†
engs = ['go .', "i lost .", 'he\'s calm .', 'i\'m home .']
fras = ['va !', 'j\'ai perdu .', 'il est calme .', 'je suis chez moi .']
for eng, fra in zip(engs, fras): # é€å¥è¿›è¡Œæœºå™¨ç¿»è¯‘å¹¶è¯„ä¼°
    # é¢„æµ‹ç¿»è¯‘ç»“æœï¼ˆåŒ…å«æ³¨æ„åŠ›æƒé‡åºåˆ—ï¼‰
    translation, dec_attention_weight_seq = common.predict_seq2seq(
        net,           # è®­ç»ƒå¥½çš„seq2seqæ¨¡å‹
        eng,           # å¾…ç¿»è¯‘çš„è‹±æ–‡å¥å­
        src_vocab,     # æºè¯­è¨€è¯æ±‡è¡¨
        tgt_vocab,     # ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨
        num_steps,     # æœ€å¤§åºåˆ—é•¿åº¦
        device,        # è®¡ç®—è®¾å¤‡ï¼ˆGPU/CPUï¼‰
        True           # è¿”å›æ³¨æ„åŠ›æƒé‡
    )
    # è®¡ç®—BLEU-2åˆ†æ•°ï¼ˆåŒè¯­è¯„ä¼°æ›¿æ‰‹ï¼‰
    print(f'{eng} => {translation}, ',
          f'bleu {common.bleu(translation, fra, k=2):.3f}')

# æå–ç¼–ç å™¨å„å±‚æ³¨æ„åŠ›æƒé‡
enc_attention_weights = torch.cat(net.encoder.attention_weights, 0)  # æ‹¼æ¥æ‰€æœ‰å±‚
enc_attention_weights = enc_attention_weights.reshape((
    num_layers,    # 2å±‚ç¼–ç å™¨
    num_heads,     # 4ä¸ªæ³¨æ„åŠ›å¤´
    -1,            # è‡ªåŠ¨è®¡ç®—ç»´åº¦ï¼ˆæºåºåˆ—é•¿åº¦ï¼‰
    num_steps      # ç›®æ ‡åºåˆ—é•¿åº¦
))
print(f"ç¼–ç å™¨æ³¨æ„åŠ›æƒé‡ï¼š{enc_attention_weights.shape}")

# å¯è§†åŒ–ç¼–ç å™¨è‡ªæ³¨æ„åŠ›çƒ­å›¾
common.show_heatmaps(
    enc_attention_weights.cpu(),  # è½¬ä¸ºCPUå¼ é‡
    xlabel='Key positions',  # æ¨ªè½´ï¼šé”®ä½ç½®
    ylabel='Query positions',  # çºµè½´ï¼šæŸ¥è¯¢ä½ç½®
    titles=['Head %d' % i for i in range(1, 5)],  # 4ä¸ªå¤´çš„æ ‡é¢˜
    figsize=(7, 3.5)  # å›¾åƒå°ºå¯¸
)

# è§£ç å™¨æ³¨æ„åŠ›æƒé‡å¤„ç†
# äºŒç»´åˆ—è¡¨æ„å»ºï¼šæŒ‰æ—¶é—´æ­¥ã€å±‚ã€æ³¨æ„åŠ›ç±»å‹ã€å¤´å±•å¼€æƒé‡
dec_attention_weights_2d = [head[0].tolist()
                            for step in dec_attention_weight_seq # éå†æ—¶é—´æ­¥
                            for attn in step    # éå†è§£ç å™¨å±‚ï¼ˆattnï¼Œå³æ¯å±‚çš„æ³¨æ„åŠ›æ•°æ®ï¼‰
                            for blk in attn     # éå†æ³¨æ„åŠ›ç±»å‹ï¼ˆblkï¼Œå³ è‡ªæ³¨æ„åŠ›/äº¤å‰æ³¨æ„åŠ›ï¼‰
                            for head in blk]    # éå†æ³¨æ„åŠ›å¤´

# è½¬æ¢ä¸ºDataFrameå¹¶å¡«å……ç¼ºå¤±å€¼
# ç¼ºå¤±å€¼å¤„ç†ï¼šä½¿ç”¨fillna(0.0)å°†NaNå¡«å……ä¸º0
dec_attention_weights_filled = torch.tensor(
    pd.DataFrame(dec_attention_weights_2d).fillna(0.0).values)

# é‡å¡‘ä¸º5ç»´å¼ é‡ï¼š[æ—¶é—´æ­¥, 2ç§ç±»å‹, å±‚æ•°, å¤´æ•°, åºåˆ—é•¿åº¦]
dec_attention_weights = dec_attention_weights_filled.reshape((-1, 2, num_layers, num_heads, num_steps))

# åˆ†ç¦»ä¸¤ç§æ³¨æ„åŠ›ç±»å‹
dec_self_attention_weights, dec_inter_attention_weights = \
    dec_attention_weights.permute(1, 2, 3, 0, 4) # è°ƒæ•´ç»´åº¦é¡ºåº
# æ‰“å°ç»´åº¦ç¡®è®¤
print(f"è‡ªæ³¨æ„åŠ›ï¼š\n{dec_self_attention_weights.shape}")
print(f"äº¤å‰æ³¨æ„åŠ›ï¼š\n{dec_inter_attention_weights.shape}")

# Plusonetoincludethebeginning-of-sequencetoken
# å¯è§†åŒ–è§£ç å™¨è‡ªæ³¨æ„åŠ›çƒ­å›¾ï¼ˆåŒ…å«èµ·å§‹ç¬¦ï¼‰
common.show_heatmaps(
    dec_self_attention_weights[:, :, :, :len(translation.split()) + 1],
    xlabel='Key positions', ylabel='Query positions',
    titles=['Head %d' % i for i in range(1, 5)], figsize=(7, 3.5))

# å¯è§†åŒ–è§£ç å™¨äº¤å‰æ³¨æ„åŠ›çƒ­å›¾ï¼ˆç¼–ç å™¨-è§£ç å™¨ï¼‰
common.show_heatmaps(
    dec_inter_attention_weights, xlabel='Key positions',
    ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)],
    figsize=(7, 3.5))


plt.pause(4444)  # é—´éš”çš„ç§’æ•°ï¼š 4s




