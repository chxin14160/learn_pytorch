import torch
from torch import nn
import common
from torch.nn import functional as F


# ä¸‹è½½å™¨ä¸æ•°æ®é›†é…ç½®
# ä¸º time_machine æ•°æ®é›†æ³¨å†Œä¸‹è½½ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡ä»¶è·¯å¾„å’Œæ ¡éªŒå“ˆå¸Œå€¼ï¼ˆç”¨äºéªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼‰
downloader = common.C_Downloader()
DATA_HUB = downloader.DATA_HUB  # å­—å…¸ï¼Œå­˜å‚¨æ•°æ®é›†åç§°ä¸ä¸‹è½½ä¿¡æ¯
DATA_URL = downloader.DATA_URL  # åŸºç¡€URLï¼ŒæŒ‡å‘æ•°æ®é›†çš„å­˜å‚¨ä½ç½®

DATA_HUB['time_machine'] = (DATA_URL + 'timemachine.txt',
                                '090b5e7e70c295757f55df93cb0a180b9691891a')

batch_size, num_steps = 32, 35  # æ¯ä¸ªå°æ‰¹é‡åŒ…å«32ä¸ªå­åºåˆ—ï¼Œæ¯ä¸ªå­åºåˆ—çš„è¯å…ƒæ•°ä¸º35
train_iter, vocab = common.load_data_time_machine(downloader, batch_size, num_steps)  # è¯è¡¨å¯¹è±¡


'''
RNNæ¨¡å‹ç±»
åŠŸèƒ½ï¼šå®ç°RNNçš„å‰å‘ä¼ æ’­
å¯¹è¾“å…¥åºåˆ—çš„æ¯ä¸ªæ—¶é—´æ­¥ï¼Œè®¡ç®—éšè—çŠ¶æ€å’Œè¾“å‡º
è¾“å…¥inputså½¢çŠ¶ä¸º (æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)ï¼ˆå®é™…åœ¨è°ƒç”¨å‰ä¼šè½¬æˆone-hotï¼‰
è¯¥å‡½æ•°è¿”å›æ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡ºï¼ˆæ‹¼æ¥æˆä¸€ä¸ªå¼ é‡ï¼‰å’Œæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€
'''
class RNNModelScratch: #@save
    """ä»é›¶å¼€å§‹å®ç°çš„å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹"""
    def __init__(self, vocab_size, num_hiddens, device,
                 get_params, init_state, forward_fn):
        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens # è¯è¡¨å¤§å°,éšè—å±‚å¤§å°
        self.params = get_params(vocab_size, num_hiddens, device)   # åˆå§‹åŒ–å‚æ•°
        self.init_state, self.forward_fn = init_state, forward_fn   # åˆå§‹åŒ–éšè—çŠ¶æ€çš„å‡½æ•°,å‰å‘ä¼ æ’­å‡½æ•°

    """
    æ¨¡å‹è°ƒç”¨æ–¹æ³•ï¼ˆå‰å‘ä¼ æ’­ï¼‰
    å‚æ•°:
    X: è¾“å…¥åºåˆ—ï¼Œå½¢çŠ¶ä¸º (æ‰¹é‡å¤§å°, æ—¶é—´æ­¥æ•°é‡)ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯è¯ç´¢å¼•ï¼ˆæ•´æ•°ï¼‰
    state: éšè—çŠ¶æ€
    è¿”å›:è¾“å‡ºå’Œæ–°çš„éšè—çŠ¶æ€
    __call__å®ç°åï¼Œè¯¥ç±»çš„å®ä¾‹å°±å¯ä»¥è¢«å½“ä½œå‡½æ•°ä½¿ç”¨ï¼Œ
    å³é€šè¿‡`instance(arguments)`çš„æ–¹å¼è°ƒç”¨è§¦å‘`__call__`æ–¹æ³•çš„æ‰§è¡Œ
    è¿™é‡Œï¼šåˆ›å»ºRNNModelScratchçš„å®ä¾‹ï¼ˆä¾‹å¦‚netï¼‰åï¼Œå¯ä»¥åƒå‡½æ•°ä¸€æ ·è°ƒç”¨è¿™ä¸ªå®ä¾‹ğŸ‘‡
    net = RNNModelScratch(len(vocab), num_hiddens, common.try_gpu(), get_params,
                        init_rnn_state, rnn) # åˆ›å»ºæ¨¡å‹å®ä¾‹
    """
    def __call__(self, X, state):
        # å°†è¾“å…¥Xè½¬æ¢ä¸ºone-hotç¼–ç 
        # X.T: è½¬ç½®ä¸º (æ—¶é—´æ­¥æ•°é‡, æ‰¹é‡å¤§å°)
        # one_hot: è½¬æ¢ä¸º (æ—¶é—´æ­¥æ•°é‡, æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)
        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)
        return self.forward_fn(X, state, self.params) # è°ƒç”¨å‰å‘ä¼ æ’­å‡½æ•°

    def begin_state(self, batch_size, device):
        """è·å–åˆå§‹éšè—çŠ¶æ€"""
        return self.init_state(batch_size, self.num_hiddens, device) # è¿”å›åˆå§‹éšè—çŠ¶æ€


# é—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰çš„ä»é›¶å¼€å§‹å®ç°
def learn_gru_StartFromScratch():
    # 1ã€åˆå§‹åŒ–æ¨¡å‹å‚æ•°
    """
    åˆå§‹åŒ– é—¨æ§å¾ªç¯å•å…ƒGRU çš„æ¨¡å‹å‚æ•°
    æƒé‡ä½¿ç”¨å°éšæœºæ•°åˆå§‹åŒ–ï¼Œåç½®åˆå§‹åŒ–ä¸º0
    åŒ…æ‹¬ï¼šè¾“å…¥åˆ°éšè—å±‚ã€éšè—å±‚åˆ°éšè—å±‚ã€éšè—å±‚åˆ°è¾“å‡ºå±‚çš„æƒé‡ä»¥åŠç›¸åº”çš„åç½®
    å‚æ•°:
    vocab_size : è¯è¡¨å¤§å° (è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦)
    num_hiddens: éšè—å±‚å¤§å°
    device     : è®¡ç®—è®¾å¤‡ (CPU/GPU)
    è¿”å›:
    params: åŒ…å«æ‰€æœ‰å‚æ•°çš„åˆ—è¡¨
    """
    def get_params(vocab_size, num_hiddens, device):
        num_inputs = num_outputs = vocab_size # è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦éƒ½æ˜¯è¯è¡¨å¤§å°ï¼ˆå­—ç¬¦çº§ï¼‰

        def normal(shape):  # å®šä¹‰æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–å‡½æ•°
            """ç”Ÿæˆæœä»æ­£æ€åˆ†å¸ƒçš„éšæœºå¼ é‡"""
            # ç”Ÿæˆæœä»æ­£æ€åˆ†å¸ƒçš„éšæœºå‚æ•°ï¼Œä¹˜ä»¥0.01ä½¿å…¶å€¼è¾ƒå°ï¼Œæœ‰åˆ©äºè®­ç»ƒç¨³å®šæ€§
            return torch.randn(size=shape, device=device)*0.01 # ç”Ÿæˆå°éšæœºæ•°

        def three(): # ç”Ÿæˆä¸é—¨æ§å’Œå€™é€‰éšçŠ¶æ€ç›¸å…³çš„ä¸‰ç»„å‚æ•°ï¼ˆè¾“å…¥æƒé‡ã€å¾ªç¯æƒé‡ã€åç½®ï¼‰
            """è¿”å›ä¸‰ä¸ªå‚æ•°ç»„ï¼š(è¾“å…¥æƒé‡, å¾ªç¯æƒé‡, åç½®)"""
            return (normal((num_inputs, num_hiddens)),       # è¾“å…¥åˆ°éšè—å±‚çš„æƒé‡
                    normal((num_hiddens, num_hiddens)),      # éšè—å±‚åˆ°éšè—å±‚çš„æƒé‡
                    torch.zeros(num_hiddens, device=device)) # åç½®ï¼ˆåˆå§‹åŒ–ä¸º0ï¼‰

        # ä¸ºGRUçš„ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼ˆæ›´æ–°é—¨ã€é‡ç½®é—¨ã€å€™é€‰çŠ¶æ€ï¼‰åˆ†åˆ«åˆ›å»ºå‚æ•°
        W_xz, W_hz, b_z = three()  # æ›´æ–°é—¨å‚æ•° (Zé—¨) : æ§åˆ¶æ–°æ—§çŠ¶æ€æ··åˆæ¯”ä¾‹
        W_xr, W_hr, b_r = three()  # é‡ç½®é—¨å‚æ•° (Ré—¨) : æ§åˆ¶å†å²ä¿¡æ¯é‡ç½®ç¨‹åº¦
        W_xh, W_hh, b_h = three()  # å€™é€‰éšçŠ¶æ€å‚æ•° : è®¡ç®—ä¸´æ—¶æ–°çŠ¶æ€

        # è¾“å‡ºå±‚å‚æ•°å•ç‹¬åˆå§‹åŒ– : å°†éšçŠ¶æ€æ˜ å°„åˆ°è¾“å‡ºç©ºé—´
        W_hq = normal((num_hiddens, num_outputs))       # éšè—å±‚åˆ°è¾“å‡ºå±‚çš„æƒé‡
        b_q = torch.zeros(num_outputs, device=device)   # è¾“å‡ºå±‚åç½®
        # å°†æ‰€æœ‰å‚æ•°æ”¾å…¥åˆ—è¡¨ï¼Œå¹¶é™„åŠ æ¢¯åº¦ï¼ˆç»„åˆæ‰€æœ‰å‚æ•°å¹¶å¯ç”¨æ¢¯åº¦è¿½è¸ªï¼‰
        params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]
        for param in params: # è®¾ç½®ä¸ºéœ€è¦æ¢¯åº¦
            param.requires_grad_(True)  # å¯ç”¨è‡ªåŠ¨å¾®åˆ†(å¼€å¯æ¢¯åº¦è¿½è¸ª)
        return params # è¿”å›æ¨¡å‹å‚æ•°åˆ—è¡¨

    # 2ã€å®šä¹‰è®­ç»ƒ
    '''
    åˆå§‹åŒ–GRUçš„éšè—çŠ¶æ€
    åŠŸèƒ½ï¼šè¿”å›åˆå§‹çš„éšè—çŠ¶æ€ï¼ˆä¸€ä¸ªå…¨é›¶å¼ é‡ï¼‰ï¼Œå½¢çŠ¶ä¸º (batch_size, num_hiddens)
    batch_size : æ‰¹é‡å¤§å°
    num_hiddens: éšè—å±‚å¤§å°
    device     : è®¡ç®—è®¾å¤‡
    è¿”å›:åŒ…å«åˆå§‹éšè—çŠ¶æ€çš„å…ƒç»„ï¼ˆå…¨é›¶å¼ é‡ï¼‰(H0,)
    è¯´æ˜ï¼šåœ¨è®­ç»ƒå¼€å§‹æ—¶æˆ–å¤„ç†æ–°åºåˆ—æ—¶ï¼ŒéšçŠ¶æ€éœ€è¦åˆå§‹åŒ–ä¸ºé›¶
    '''
    def init_gru_state(batch_size, num_hiddens, device):
        # åˆå§‹åŒ–éšçŠ¶æ€ä¸ºå…¨0ï¼Œå½¢çŠ¶ä¸º (batch_size, num_hiddenséšè—å•å…ƒæ•°)
        return (torch.zeros((batch_size, num_hiddens), device=device), ) # åˆå§‹éšè—çŠ¶æ€ä¸ºå…¨0

    '''
    GRUå‰å‘ä¼ æ’­è®¡ç®—
    æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºæ˜¯çº¿æ€§å˜æ¢åçš„éšçŠ¶æ€ï¼ˆæœªç»è¿‡softmaxï¼Œå› ä¸ºè®­ç»ƒæ—¶ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ä¼šåŒ…å«softmaxï¼‰
    inputs: è¾“å…¥åºåˆ— (æ—¶é—´æ­¥æ•°é‡, æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)
    state : åˆå§‹éšè—çŠ¶æ€çš„å…ƒç»„ (H0,)
    params: æ¨¡å‹å‚æ•°åˆ—è¡¨ [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]
    è¿”å›:
    outputs  : æ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡ºï¼Œå½¢çŠ¶ä¸º (æ—¶é—´æ­¥æ•°é‡ * æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)
    (H,): æ›´æ–°åçš„æœ€ç»ˆéšçŠ¶æ€
    '''
    def gru(inputs, state, params):
        W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params # è§£åŒ…å‚æ•°
        H, = state       # è§£åŒ…å½“å‰éšè—çŠ¶æ€ (batch_size, num_hiddens)
        outputs = []     # ç”¨äºå­˜å‚¨æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        for X in inputs: # éå†è¾“å…¥åºåˆ—çš„æ¯ä¸ªæ—¶é—´æ­¥
            # æ›´æ–°é—¨è®¡ç®—ï¼šå†³å®šä¿ç•™å¤šå°‘æ—§çŠ¶æ€ (æ§åˆ¶çŠ¶æ€æ›´æ–°ç¨‹åº¦)
            # Z_t = Ïƒ(X_t * W_xz + H_{t-1} * W_hz + b_z)
            Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z) # å½¢çŠ¶: (batch_size, num_hiddens)

            # é‡ç½®é—¨è®¡ç®—ï¼šå†³å®šé‡ç½®å¤šå°‘å†å²ä¿¡æ¯
            # R_t = Ïƒ(X_t * W_xr + H_{t-1} * W_hr + b_r)
            R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r) # å½¢çŠ¶: (batch_size, num_hiddens)

            # å€™é€‰éšçŠ¶æ€è®¡ç®—ï¼šï¼ˆä½¿ç”¨é‡ç½®é—¨æ§åˆ¶å†å²ä¿¡æ¯å½±å“ï¼‰
            # \tilde{H}_t = tanh(X_t * W_xh + (R_t âŠ™ H_{t-1}) * W_hh + b_h)
            H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h) # å½¢çŠ¶: (batch_size, num_hiddens)

            # æ›´æ–°æœ€ç»ˆéšçŠ¶æ€ï¼šæ··åˆæ—§çŠ¶æ€å’Œæ–°å€™é€‰çŠ¶æ€ï¼šH_t = Z_t âŠ™ H_{t-1} + (1 - Z_t) âŠ™ \tilde{H}_t
            H = Z * H + (1 - Z) * H_tilda # å½¢çŠ¶: (batch_size, num_hiddens)

            # è®¡ç®—å½“å‰æ—¶é—´æ­¥è¾“å‡ºï¼Œå³ è¾“å‡ºå±‚ï¼šY_t = H_t * W_hq + b_q
            Y = H @ W_hq + b_q            # å½¢çŠ¶: (batch_size, vocab_size)
            outputs.append(Y)  # ä¿å­˜è¾“å‡º
        # æ²¿æ—¶é—´æ­¥ç»´åº¦æ‹¼æ¥æ‰€æœ‰è¾“å‡ºï¼ˆå½¢çŠ¶ï¼šæ—¶é—´æ­¥æ•°Ã—æ‰¹é‡å¤§å°Ã—è¯è¡¨å¤§å°ï¼‰
        # (H,) è¡¨ç¤ºåªåŒ…å«ä¸€ä¸ªå…ƒç´ Hçš„å…ƒç»„ï¼ˆtupleï¼‰ï¼Œä½†çœŸæ­£å®šä¹‰å…ƒç»„çš„æ˜¯é€—å·ï¼Œè€Œä¸æ˜¯åœ†æ‹¬å·
        # å¦‚æœå†™(H)ï¼Œè¿™åªæ˜¯å¸¦æ‹¬å·çš„è¡¨è¾¾å¼ï¼Œç­‰åŒäº`H`ï¼Œè€Œä¸æ˜¯å…ƒç»„ã€‚ä¸ºäº†è¡¨ç¤ºè¿™æ˜¯åªæœ‰ä¸€ä¸ªå…ƒç´ çš„å…ƒç»„ï¼Œéœ€åœ¨å…ƒç´ ååŠ é€—å·ã€‚æ‰€ä»¥ï¼š
        # (H)  æ˜¯ä¸€ä¸ªè¡¨è¾¾å¼ï¼Œå…¶å€¼ä¸ºH
        # (H,) æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ä¸€ä¸ªå…ƒç´ H
        return torch.cat(outputs, dim=0), (H,) # è¿”å›è¾“å‡ºå’Œæœ€åä¸€ä¸ªéšè—çŠ¶æ€

    # 3ã€è®­ç»ƒä¸é¢„æµ‹
    # è¯è¡¨å¤§å°ã€éšè—å±‚å¤§å°256ã€è®¾å¤‡
    vocab_size, num_hiddens, device = len(vocab), 256, common.try_gpu()
    num_epochs, lr = 500, 1 # è®­ç»ƒå‘¨æœŸå³è¿­ä»£å‘¨æœŸä¸º500ï¼Œå³è®­ç»ƒ500è½®ï¼›å­¦ä¹ ç‡ä¸º1ï¼ˆè¾ƒé«˜å­¦ä¹ ç‡å› ä»0å®ç°ï¼‰
    model = RNNModelScratch(len(vocab), num_hiddens, device, get_params,
                                init_gru_state, gru) # åˆ›å»ºæ¨¡å‹å®ä¾‹
    common.train_ch8(model, train_iter, vocab, lr, num_epochs, device) # è®­ç»ƒæ¨¡å‹
# learn_gru_StartFromScratch()



# å®šä¹‰å®Œæ•´çš„RNNæ¨¡å‹ç±»
# rnn_layeråªåŒ…å«éšè—çš„å¾ªç¯å±‚ï¼Œå› æ­¤å¦å¤–è¿˜éœ€è¦åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„è¾“å‡ºå±‚
class RNNModel(nn.Module):
    """å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹"""
    def __init__(self, rnn_layer, vocab_size, **kwargs):
        super(RNNModel, self).__init__(**kwargs)
        self.rnn = rnn_layer                    # ä¼ å…¥çš„RNNå±‚
        self.vocab_size = vocab_size            # è¯è¡¨å¤§å°
        self.num_hiddens = self.rnn.hidden_size # ä»RNNå±‚è·å–éšè—å•å…ƒæ•°

        # åˆ¤æ–­RNNæ˜¯å¦ä¸ºåŒå‘ï¼šè‹¥RNNæ˜¯åŒå‘(ä¹‹åå°†ä»‹ç»)ï¼Œnum_directionsä¸º2ï¼Œå¦åˆ™ä¸º1
        if not self.rnn.bidirectional: # å•å‘RNN: num_directions = 1
            self.num_directions = 1
            # çº¿æ€§å±‚: å°†éšè—çŠ¶æ€æ˜ å°„åˆ°è¯è¡¨å¤§å°
            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)
        else:                          # åŒå‘RNN: num_directions = 2
            self.num_directions = 2
            # å¯¹äºåŒå‘RNNï¼Œéœ€è¦å°†ä¸¤ä¸ªæ–¹å‘çš„éšè—çŠ¶æ€æ‹¼æ¥
            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)

    """ å‰å‘ä¼ æ’­å‡½æ•°
    inputs: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°, æ—¶é—´æ­¥æ•°)
    state: éšè—çŠ¶æ€
    """
    def forward(self, inputs, state):
        # è¾“å…¥è½¬ä¸ºone-hotç¼–ç 
        # inputs.T: è½¬ç½®ä¸º(æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°)
        # one-hotç¼–ç åå½¢çŠ¶: (æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)
        X = F.one_hot(inputs.T.long(), self.vocab_size)
        X = X.to(torch.float32)         # ç‹¬çƒ­å¼ é‡è½¬æ¢ä¸ºfloat32 (PyTorchçš„çº¿æ€§å±‚éœ€è¦æµ®ç‚¹è¾“å…¥)

        # Y: æ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡ºï¼Œå½¢çŠ¶ä¸º(æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°, éšè—å•å…ƒæ•° * æ–¹å‘æ•°)
        # state: æ›´æ–°åçš„éšè—çŠ¶æ€
        Y, state = self.rnn(X, state)   # é€šè¿‡RNNå±‚

        # å…¨è¿æ¥å±‚é¦–å…ˆå°†Yçš„å½¢çŠ¶æ”¹ä¸º(æ—¶é—´æ­¥æ•°*æ‰¹é‡å¤§å°,éšè—å•å…ƒæ•°)
        # å³ é‡å¡‘Yçš„å½¢çŠ¶ä¸º (æ—¶é—´æ­¥æ•° * æ‰¹é‡å¤§å°, éšè—å•å…ƒæ•° * æ–¹å‘æ•°)
        # è¿™æ ·æ¯ä¸ªæ—¶é—´æ­¥çš„æ¯ä¸ªæ ·æœ¬éƒ½å¯ä»¥ç‹¬ç«‹å¤„ç†
        # å…¶è¾“å‡ºå½¢çŠ¶ä¸º (æ—¶é—´æ­¥æ•°*æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)
        output = self.linear(Y.reshape((-1, Y.shape[-1]))) # é€šè¿‡å…¨è¿æ¥å±‚è¿›è¡Œé¢„æµ‹
        return output, state

    # åˆå§‹åŒ–éšè—çŠ¶æ€å‡½æ•°ï¼šæ ¹æ®RNNç±»å‹(GRU/LSTM)è¿”å›é€‚å½“å½¢å¼çš„åˆå§‹çŠ¶æ€
    def begin_state(self, device, batch_size=1):
        if not isinstance(self.rnn, nn.LSTM): # å¯¹äºGRUç±»å‹çš„RNN
            # nn.GRUä»¥å¼ é‡ä½œä¸ºéšçŠ¶æ€
            # è¿”å›é›¶å¼ é‡ä½œä¸ºåˆå§‹çŠ¶æ€ï¼Œå½¢çŠ¶: (å±‚æ•° * æ–¹å‘æ•°, æ‰¹é‡å¤§å°, éšè—å•å…ƒæ•°)
            return  torch.zeros((self.num_directions * self.rnn.num_layers,
                                 batch_size, self.num_hiddens),
                                device=device)
        else: # å¯¹äºLSTMç±»å‹çš„RNN
            # nn.LSTMä»¥å…ƒç»„ä½œä¸ºéšçŠ¶æ€ï¼ŒLSTMéœ€è¦ä¸¤ä¸ªçŠ¶æ€: (éšè—çŠ¶æ€h, ç»†èƒçŠ¶æ€c)
            return (
                torch.zeros(( # éšè—çŠ¶æ€
                self.num_directions * self.rnn.num_layers,
                batch_size, self.num_hiddens), device=device),
                torch.zeros(( # ç»†èƒçŠ¶æ€
                        self.num_directions * self.rnn.num_layers,
                        batch_size, self.num_hiddens), device=device))


# é—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰çš„ç®€æ´å®ç°
def learn_gru_SimpleImplementation():
    # è¯è¡¨å¤§å°ã€éšè—å±‚å¤§å°256ã€è®¾å¤‡
    vocab_size, num_hiddens, device = len(vocab), 256, common.try_gpu()
    num_epochs, lr = 500, 1 # è®­ç»ƒå‘¨æœŸå³è¿­ä»£å‘¨æœŸä¸º500ï¼Œå³è®­ç»ƒ500è½®ï¼›å­¦ä¹ ç‡ä¸º1(ä½¿ç”¨å†…ç½®GRUæ—¶é€šå¸¸éœ€è¦è°ƒæ•´ï¼Œè¿™é‡Œä¿æŒä¸ä»é›¶å®ç°ä¸€è‡´)

    num_inputs = vocab_size # è¾“å…¥ç»´åº¦ç­‰äºè¯è¡¨å¤§å°ï¼ˆå­—ç¬¦çº§one-hotè¡¨ç¤ºï¼‰
    """
    nn.GRUå…³é”®å‚æ•°:
    - num_inputs: è¾“å…¥ç‰¹å¾ç»´åº¦ (è¯è¡¨å¤§å°)
    - num_hiddens: éšè—å±‚ç¥ç»å…ƒæ•°é‡ (256)
    - é»˜è®¤: å•å±‚ã€éåŒå‘ã€batch_first=False (åºåˆ—ç»´åº¦åœ¨å‰)
    """
    gru_layer = nn.GRU(num_inputs, num_hiddens) # åˆ›å»ºå†…ç½®GRUå±‚ï¼šè¾“å…¥ç»´åº¦, éšè—å±‚ç»´åº¦
    """
    RNNModelç±»åŠŸèƒ½:
    1. å¤„ç†è¾“å…¥æ•°æ®çš„one-hotç¼–ç 
    2. é€šè¿‡GRUå±‚è®¡ç®—éšè—çŠ¶æ€
    3. æ·»åŠ å…¨è¿æ¥è¾“å‡ºå±‚ (éšè—å±‚->è¯è¡¨)
    4. ç®¡ç†éšè—çŠ¶æ€çš„åˆå§‹åŒ–å’Œä¼ é€’
    """
    model = RNNModel(gru_layer, len(vocab)) # ä¼ å…¥GRUå±‚å’Œè¯è¡¨å¤§å°
    model = model.to(device) # å°†æ¨¡å‹ç§»åˆ°æŒ‡å®šè®¾å¤‡ (GPU/CPU)
    common.train_ch8(model, train_iter, vocab, lr, num_epochs, device) # è®­ç»ƒæ¨¡å‹
# learn_gru_SimpleImplementation()



# é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰çš„ä»é›¶å¼€å§‹å®ç°
def learn_LSTM_StartFromScratch():
    # 1ã€åˆå§‹åŒ–æ¨¡å‹å‚æ•°
    """
    åˆå§‹åŒ– é•¿çŸ­æœŸè®°å¿†ç½‘ç»œLSTM æ‰€æœ‰å¯è®­ç»ƒå‚æ•°
    æƒé‡ä½¿ç”¨å°éšæœºæ•°åˆå§‹åŒ–ï¼Œåç½®åˆå§‹åŒ–ä¸º0
    å‚æ•°:
    vocab_size : è¯è¡¨å¤§å° (è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦)
    num_hiddens: éšè—å±‚æ•°é‡
    device     : è®¡ç®—è®¾å¤‡ (CPU/GPU)
    è¿”å›:
    params: åŒ…å«æ‰€æœ‰å‚æ•°çš„åˆ—è¡¨
    """
    def get_lstm_params(vocab_size, num_hiddens, device):
        num_inputs = num_outputs = vocab_size # è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦éƒ½æ˜¯è¯è¡¨å¤§å°ï¼ˆå­—ç¬¦çº§è¯­è¨€æ¨¡å‹ï¼‰

        def normal(shape): # å®šä¹‰æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–å‡½æ•°
            """ç”Ÿæˆæœä»æ­£æ€åˆ†å¸ƒçš„éšæœºå¼ é‡ï¼ˆç¼©å°åˆå§‹å€¼èŒƒå›´ï¼‰"""
            # ç”Ÿæˆæœä»æ­£æ€åˆ†å¸ƒçš„éšæœºå‚æ•°ï¼Œä¹˜ä»¥0.01ä½¿å…¶å€¼è¾ƒå°ï¼Œæœ‰åˆ©äºè®­ç»ƒç¨³å®šæ€§
            return torch.randn(size=shape, device=device)*0.01 # ç”Ÿæˆå°éšæœºæ•°

        def three():
            """è¿”å›ä¸‰ä¸ªå‚æ•°ç»„ï¼š(è¾“å…¥æƒé‡, å¾ªç¯æƒé‡, åç½®)"""
            return (normal((num_inputs, num_hiddens)),        # è¾“å…¥åˆ°éšè—å±‚çš„æƒé‡
                    normal((num_hiddens, num_hiddens)),       # éšè—å±‚åˆ°éšè—å±‚çš„æƒé‡
                    torch.zeros(num_hiddens, device=device))  # åç½®ï¼ˆåˆå§‹åŒ–ä¸º0ï¼‰

        W_xi, W_hi, b_i = three()  # è¾“å…¥é—¨å‚æ•° (æ§åˆ¶æ–°ä¿¡æ¯æµå…¥)
        W_xf, W_hf, b_f = three()  # é—å¿˜é—¨å‚æ•° (æ§åˆ¶æ—§ä¿¡æ¯ä¿ç•™)
        W_xo, W_ho, b_o = three()  # è¾“å‡ºé—¨å‚æ•° (æ§åˆ¶ä¿¡æ¯è¾“å‡º)
        W_xc, W_hc, b_c = three()  # å€™é€‰è®°å¿†å…ƒå‚æ•° (æ–°è®°å¿†è®¡ç®—)
        # è¾“å‡ºå±‚å‚æ•°å•ç‹¬åˆå§‹åŒ– : å°†éšçŠ¶æ€æ˜ å°„åˆ°è¾“å‡ºç©ºé—´ï¼ˆè¯è¡¨å¤§å°ï¼‰
        W_hq = normal((num_hiddens, num_outputs))      # éšè—å±‚åˆ°è¾“å‡ºå±‚çš„æƒé‡
        b_q = torch.zeros(num_outputs, device=device)  # è¾“å‡ºå±‚åç½®ï¼ˆåˆå§‹åŒ–ä¸º0ï¼‰
        # å°†æ‰€æœ‰å‚æ•°æ”¾å…¥åˆ—è¡¨ï¼Œå¹¶é™„åŠ æ¢¯åº¦ï¼ˆç»„åˆæ‰€æœ‰å‚æ•°å¹¶å¯ç”¨æ¢¯åº¦è¿½è¸ªï¼‰
        params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,
                  b_c, W_hq, b_q]
        for param in params:  # è®¾ç½®ä¸ºéœ€è¦æ¢¯åº¦
            param.requires_grad_(True)  # å¯ç”¨è‡ªåŠ¨å¾®åˆ†(å¼€å¯æ¢¯åº¦è¿½è¸ª)
        return params # è¿”å›æ¨¡å‹å‚æ•°åˆ—è¡¨

    # 2ã€å®šä¹‰æ¨¡å‹
    '''
    åˆå§‹åŒ– LSTMçš„ éšè—çŠ¶æ€ å’Œ è®°å¿†å…ƒçŠ¶æ€
    batch_size : æ‰¹é‡å¤§å°
    num_hiddens: éšè—å±‚å¤§å°
    device     : è®¡ç®—è®¾å¤‡
    è¿”å›:åŒ…å«(åˆå§‹éšè—çŠ¶æ€, åˆå§‹è®°å¿†å…ƒçŠ¶æ€)çš„å…ƒç»„ï¼ˆå…¨é›¶å¼ é‡ï¼‰
    '''
    def init_lstm_state(batch_size, num_hiddens, device):
        # LSTMæœ‰ä¸¤ä¸ªçŠ¶æ€ï¼šéšè—çŠ¶æ€Hå’Œè®°å¿†å…ƒçŠ¶æ€Cï¼Œåˆå§‹åŒ–ä¸ºå…¨0ï¼Œå½¢çŠ¶ä¸º (batch_size, num_hiddenséšè—å•å…ƒæ•°)
        return (torch.zeros((batch_size, num_hiddens), device=device), # éšè—çŠ¶æ€ H
                torch.zeros((batch_size, num_hiddens), device=device)) # è®°å¿†å…ƒçŠ¶æ€ C

    '''
    LSTMå‰å‘ä¼ æ’­è®¡ç®—
    æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºæ˜¯çº¿æ€§å˜æ¢åçš„éšçŠ¶æ€ï¼ˆæœªç»è¿‡softmaxï¼Œå› ä¸ºè®­ç»ƒæ—¶ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ä¼šåŒ…å«softmaxï¼‰
    inputs: è¾“å…¥åºåˆ— (æ—¶é—´æ­¥åˆ—è¡¨, æ¯ä¸ªå½¢çŠ¶ä¸º[batch_size, vocab_size]) å³ (æ—¶é—´æ­¥æ•°é‡, æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)
    state : åˆå§‹éšè—çŠ¶æ€çš„å…ƒç»„ (H, C)
    params: æ¨¡å‹å‚æ•°åˆ—è¡¨
    è¿”å›:
    outputs  : æ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡ºï¼Œå½¢çŠ¶ä¸º (æ—¶é—´æ­¥æ•°é‡ * æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)
    (H, C): æ›´æ–°åçš„æœ€ç»ˆçŠ¶æ€
    '''
    def lstm(inputs, state, params):
        [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,
         W_hq, b_q] = params # è§£åŒ…å‚æ•° (å…±14ä¸ªå‚æ•°)
        (H, C) = state       # è§£åŒ…åˆå§‹çŠ¶æ€ï¼ˆH: éšè—çŠ¶æ€, C: è®°å¿†å…ƒçŠ¶æ€ï¼‰
        outputs = []         # ç”¨äºå­˜å‚¨æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        for X in inputs:     # éå†è¾“å…¥åºåˆ—çš„æ¯ä¸ªæ—¶é—´æ­¥
            # 1. è¾“å…¥é—¨ (I_t)è®¡ç®—ï¼šæ§åˆ¶æ–°ä¿¡æ¯æµå…¥
            I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i) # å½¢çŠ¶: (batch_size, num_hiddens)

            # 2. é—å¿˜é—¨ (F_t)è®¡ç®—ï¼šæ§åˆ¶æ—§ä¿¡æ¯ä¿ç•™
            F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f) # å½¢çŠ¶: (batch_size, num_hiddens)

            # 3. è¾“å‡ºé—¨ (O_t)è®¡ç®—ï¼šæ§åˆ¶ä¿¡æ¯è¾“å‡º
            O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o) # å½¢çŠ¶: (batch_size, num_hiddens)

            # 4. å€™é€‰è®°å¿†å…ƒ (C_tilda_t)è®¡ç®—ï¼šæ–°ä¿¡æ¯çš„åŸå§‹è¡¨ç¤º
            C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c) # å½¢çŠ¶: (batch_size, num_hiddens)

            # 5. æ›´æ–°è®°å¿†å…ƒ (C_t)çŠ¶æ€ï¼šé—å¿˜æ—§ä¿¡æ¯ + æ·»åŠ æ–°ä¿¡æ¯ ï¼ˆé—å¿˜é—¨æ§åˆ¶æ—§çŠ¶æ€ï¼Œè¾“å…¥é—¨æ§åˆ¶æ–°å€™é€‰çŠ¶æ€ï¼‰
            C = F * C + I * C_tilda # å½¢çŠ¶: (batch_size, num_hiddens)

            # 6. æ›´æ–°éšè—çŠ¶æ€ (H_t)ï¼šåŸºäºè®°å¿†å…ƒç”Ÿæˆæ–°éšè—çŠ¶æ€ï¼ˆè¾“å‡ºé—¨æ§åˆ¶tanh(è®°å¿†å…ƒ)çš„è¾“å‡ºï¼‰
            H = O * torch.tanh(C) # å½¢çŠ¶: (batch_size, num_hiddens)

            # 7. è®¡ç®—å½“å‰æ—¶é—´æ­¥è¾“å‡º (Y_t)
            Y = (H @ W_hq) + b_q  # å½¢çŠ¶: (batch_size, vocab_size)
            outputs.append(Y)     # ä¿å­˜è¾“å‡º
        return torch.cat(outputs, dim=0), (H, C) # æ²¿æ—¶é—´æ­¥ç»´åº¦æ‹¼æ¥æ‰€æœ‰è¾“å‡ºï¼ˆå½¢çŠ¶ï¼šæ—¶é—´æ­¥æ•°Ã—æ‰¹é‡å¤§å°Ã—è¯è¡¨å¤§å°ï¼‰

    # 3ã€è®­ç»ƒå’Œé¢„æµ‹
    # è¯è¡¨å¤§å°ã€éšè—å±‚å¤§å°256ã€è®¾å¤‡
    vocab_size, num_hiddens, device = len(vocab), 256, common.try_gpu()
    num_epochs, lr = 500, 1 # è®­ç»ƒå‘¨æœŸå³è¿­ä»£å‘¨æœŸä¸º500ï¼Œå³è®­ç»ƒ500è½®ï¼›å­¦ä¹ ç‡ä¸º1ï¼ˆè¾ƒé«˜å­¦ä¹ ç‡å› ä»é›¶å®ç°ï¼‰
    # åˆ›å»ºLSTMæ¨¡å‹å®ä¾‹ï¼ˆä½¿ç”¨RNNModelScratchç±»å°è£…ï¼Œä¼ å…¥LSTMçš„å‚æ•°åˆå§‹åŒ–ã€çŠ¶æ€åˆå§‹åŒ–å’Œå‰å‘ä¼ æ’­å‡½æ•°ï¼‰
    model = RNNModelScratch(len(vocab), num_hiddens, device, get_lstm_params,
                                init_lstm_state, lstm)
    # è®­ç»ƒæ¨¡å‹ï¼ˆtrain_iteræ˜¯æ•°æ®è¿­ä»£å™¨ï¼Œvocabæ˜¯è¯è¡¨ï¼‰
    common.train_ch8(model, train_iter, vocab, lr, num_epochs, device)
# learn_LSTM_StartFromScratch()


# é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰çš„ç®€æ´å®ç°
def learn_LSTM_SimpleImplementation():
    # è¯è¡¨å¤§å°ï¼ˆå”¯ä¸€å­—ç¬¦æ•°é‡ï¼‰ã€LSTMéšè—å±‚ç»´åº¦ï¼ˆ256ä¸ªç¥ç»å…ƒï¼‰ã€è®¾å¤‡
    vocab_size, num_hiddens, device = len(vocab), 256, common.try_gpu()
    # è®­ç»ƒå‘¨æœŸå³è¿­ä»£å‘¨æœŸä¸º500ï¼Œå³è®­ç»ƒ500è½®ï¼›
    # å­¦ä¹ ç‡ä¸º1(ä½¿ç”¨å†…ç½®GRUæ—¶é€šå¸¸éœ€è¦è°ƒæ•´ï¼Œè¿™é‡Œä¿æŒä¸ä»é›¶å®ç°ä¸€è‡´ï¼Œå®é™…ä½¿ç”¨å†…ç½®LSTMæ—¶å»ºè®®0.01-0.1)
    num_epochs, lr = 500, 1
    num_inputs = vocab_size # è¾“å…¥ç»´åº¦ç­‰äºè¯è¡¨å¤§å°ï¼ˆå­—ç¬¦çº§one-hotè¡¨ç¤ºï¼‰
    """
    nn.LSTMå…³é”®å‚æ•°:
    - input_size: è¾“å…¥ç‰¹å¾ç»´åº¦ = è¯è¡¨å¤§å°
    - hidden_size: éšè—çŠ¶æ€ç»´åº¦ = 256
    - é»˜è®¤é…ç½®:
      - å•å±‚å•å‘LSTM
      - batch_first=False (è¾“å…¥å½¢çŠ¶ä¸º[seq_len, batch, input_size])
      - ä½¿ç”¨tanhæ¿€æ´»å‡½æ•°
      - åç½®é¡¹é»˜è®¤å¯ç”¨
    """
    lstm_layer = nn.LSTM(num_inputs, num_hiddens)
    model = RNNModel(lstm_layer, len(vocab)) # ä¼ å…¥GRUå±‚å’Œè¯è¡¨å¤§å°
    """
    RNNModelç±»å°è£…äº†:
    1. è¾“å…¥å¤„ç†: å°†å­—ç¬¦ç´¢å¼•è½¬æ¢ä¸ºå‘é‡ï¼ˆå¯èƒ½ä½¿ç”¨åµŒå…¥å±‚æˆ–one-hotï¼‰
    2. LSTMå±‚: æ ¸å¿ƒåºåˆ—å»ºæ¨¡
    3. è¾“å‡ºå±‚: å…¨è¿æ¥å±‚ (256éšè—å•å…ƒ â†’ è¯è¡¨å¤§å°)
    4. çŠ¶æ€ç®¡ç†: è‡ªåŠ¨å¤„ç†LSTMçš„éšè—çŠ¶æ€å’Œè®°å¿†å…ƒçŠ¶æ€
    
    é¢„æœŸç»“æ„:
    class RNNModel(nn.Module):
        def __init__(self, rnn_layer, vocab_size):
            super().__init__()
            self.rnn = rnn_layer
            self.vocab_size = vocab_size
            self.num_hiddens = rnn_layer.hidden_size
            # è¾“å‡ºå±‚
            self.dense = nn.Linear(self.num_hiddens, vocab_size)
    
        def forward(self, inputs, state):
            # è¾“å…¥è½¬æ¢ (batch, seq_len) â†’ (seq_len, batch, vocab_size)
            X = F.one_hot(inputs.T.long(), self.vocab_size).float()
            # LSTMè®¡ç®—
            Y, state = self.rnn(X, state)
            # è¾“å‡ºå±‚
            output = self.dense(Y.reshape(-1, Y.shape[-1]))
            return output, state
    
        def begin_state(self, batch_size=1):
            return (torch.zeros(1, batch_size, self.num_hiddens),
                    torch.zeros(1, batch_size, self.num_hiddens))
    """

    model = model.to(device) # å°†æ¨¡å‹ç§»åˆ°æŒ‡å®šè®¾å¤‡ (GPU/CPU)
    common.train_ch8(model, train_iter, vocab, lr, num_epochs, device) # è®­ç»ƒæ¨¡å‹
# learn_LSTM_SimpleImplementation()



























